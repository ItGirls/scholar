{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scholar is a framework for document modeling, much like LDA, but with the ability to flexibly incorporate metadata, with some similarity to the structural topic model. It can scale to large numbers of covariates, runs in python, and offers GPU support for fast exploration of a corpus of documents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we'll use a toy corpus of political press releases in order to demonstrate the functionality and interface of Scholar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code\n",
    "\n",
    "If you're looking at this tutorial, you have presumably already downloaded/cloned the Scholar repo. If not, you can clone it using: \n",
    "\n",
    "`git clone git@github.com:dallascard/scholar.git`\n",
    "\n",
    "(if you don't have git set up, you can just download the repo from https://github.com/dallascard/scholar)\n",
    "\n",
    "Scholar has not yet been packaged us as a full python packge. As such, we will just run commands from the scholar directory, so switch into it:\n",
    "\n",
    "`cd /path/to/scholar`\n",
    "\n",
    "(the directory that contains this notebook)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment\n",
    "\n",
    "Create new python environment for running scholar. We recommend using Anaconda, but it is also possible to do this using virtualenv and pip. Assuming you are using conda, run the following three commands, one at a time, and follow the prompts:\n",
    "\n",
    "`conda create -n scholar python=3`\n",
    "\n",
    "`source activate scholar`\n",
    "\n",
    "`conda install ipython notebook numpy scipy pandas matplotlib gensim pytorch torchvision -c pytorch`\n",
    "\n",
    "You should also now quit this notebook and reload it from with the scholar environment (i.e. after running `source activate scholar` in the shell)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data\n",
    "\n",
    "For this tutorial, we'll be using a subset of the Congressional press release corpus created by Justin Grimmer.\n",
    "\n",
    "A compressed file with press releases from six senators can be found in this repo. To expand it, run\n",
    "\n",
    "`tar -xzf tutorial.tar.gz`\n",
    "\n",
    "which will create a Â directory called  `tutorial/CongressPressExpand/`\n",
    "\n",
    "For those who are interested, the full dataset (Press.tar; 282Mb) can be downloaded from https://dataverse.harvard.edu/dataset.xhtml?persistentId=hdl:1902.1/14596"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Import\n",
    "\n",
    "To use scholar, it is necessary to get the data into the proper format. To do this, the easiest thing to do is to write a script to convert the documents into a single file, where each line corresponds to one document, represented as a JSON object. Each JSON object should have at least one field called \"text\", but it can also contain other metadata fields.\n",
    "\n",
    "We have included a script to convert a subset of the Senatorial press releases into this format, which can be used as a starting point for your own project.\n",
    "\n",
    "If running this from the command line, it would be run as\n",
    "\n",
    "`python import_congress_press.py tutorial/CongressPressExpand tutorial/congress/`\n",
    "\n",
    "Since we are running this in a notebook, we will run it by importing the package, and calling the `main()` function with the corresponding arguments in a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python import_congress_press tutorial/CongressPressExpand tutorial/congress\n",
      "274 files from Sanders\n",
      "709 files from Obama\n",
      "358 files from Klobuchar\n",
      "293 files from McCain\n",
      "614 files from Graham\n",
      "235 files from Coburn\n",
      "Saving files to tutorial/congress\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "import import_congress_press\n",
    "script = 'import_congress_press'\n",
    "args = 'tutorial/CongressPressExpand tutorial/congress'\n",
    "print(\"python\", script, args)\n",
    "import_congress_press.main(args.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This creates two files in the output directory (`/tutorial/congress/`):\n",
    "- `train.jsonlist` contains one press release per line, in JSON format, including fields for the text of the press release, as well as senator name, party, date, year, and month\n",
    "- `train.score.csv` contains DW-nominate scores for 6 senators from the 110th congress, with one score for each document in `train.jsonlist` (in the same order)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To inspect a document, we can use the `json` library to load it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id : 10Apr2007Sanders238.txt\n",
      "text : SEIZE THE OPPORTUNITY FOR MAJOR BREAKTHROUGHS IN HEALTH CARE   The Senate this week is considering a bill, cosponsored by Sen. Bernie Sanders, that would expand and encourage federal funding of human embryonic stem cell research. President Bush in 2001 cut off federal funding for research involving new embryonic stem cells, which has dramatically stalled this critical area of medical research.      \"My hope is that, as a result of increased pressure from scientists, physicians and the American people, the president will change his position or, if he does not, that the Congress will have enough votes to override his veto and establish unrestricted federal funding for stem cell research,\" Sanders said. \"The potential is now available for major breakthroughs in Parkinson's disease, Alzheimer's, diabetes, spinal cord injury, stroke, heart disease and many other illnesses. We must seize the opportunity.\"     View a copy of the Bill - S. 5 at http://sanders.senate.gov/files/S_5.pdf    Read a summary of the bill - S. 5 at http://www.sanders.senate.gov/news/record.cfm?id=272151    Read a Congressional Research Service background report on stem cell research at http://sanders.senate.gov/files/Stem%20Cells.pdf.    \n",
      "senator : Sanders\n",
      "date : 10Apr2007\n",
      "year : 2007\n",
      "month : Apr\n",
      "party : D\n",
      "score : -0.717\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "with open(os.path.join('tutorial', 'congress', 'train.jsonlist')) as f:\n",
    "    lines = f.readlines()\n",
    "first_doc = json.loads(lines[0])\n",
    "for key, value in first_doc.items():\n",
    "    print(key, ':', value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we had documents that we wanted to use as a test set, we could create a `test.jsonlist` object in the same manner."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to use a preprocessing script we have provided to convert the documents from JSON format into a numerical representation. It works by creating a vocabulary, filtering out numbers, punctuation, and some other tokens, and saving the document-term count matrix. \n",
    "\n",
    "The preprocessing script can also simultaneously pull out various metadata attributes (like author or year) from the JSON objects, and convert them into one-hot representations, which will be saved as .csv files.\n",
    "\n",
    "For other types of metadata, such as continously-valued data, you will need to create the corresponding .csv files manually, as we did above for `train.score.csv`. All that matters is that the order of the rows is the same as the the order of documents in `train.jsonlist`. Also, scholar will expect the file name to be `train.field_name.csv` (or \"test\" rather than \"train\" for test data)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see the full set of options for any command, try running it with the `-h` option. Again, in the shell, this would be run as:\n",
    "\n",
    "`python preprocess_data.py -h`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python preprocess_data.py -h\n",
      "Usage: ipykernel_launcher.py train.jsonlist output_dir\n",
      "\n",
      "Options:\n",
      "  -h, --help            show this help message and exit\n",
      "  --label=LABEL         field(s) to use as label (comma-separated):\n",
      "                        default=none\n",
      "  --test=TEST           Test data (test.jsonlist): default=none\n",
      "  --train-prefix=TRAIN_PREFIX\n",
      "                        Output prefix for training data: default=train\n",
      "  --test-prefix=TEST_PREFIX\n",
      "                        Output prefix for test data: default=test\n",
      "  --stopwords=STOPWORDS\n",
      "                        List of stopwords to exclude [None|mallet|snowball]:\n",
      "                        default=snowball\n",
      "  --min-doc-count=MIN_DOC_COUNT\n",
      "                        Exclude words that occur in less than this number of\n",
      "                        documents\n",
      "  --max-doc-freq=MAX_DOC_FREQ\n",
      "                        Exclude words that occur in more than this proportion\n",
      "                        of documents\n",
      "  --keep-num            Keep tokens made of only numbers: default=False\n",
      "  --keep-alphanum       Keep tokens made of a mixture of letters and numbers:\n",
      "                        default=False\n",
      "  --strip-html          Strip HTML tags: default=False\n",
      "  --no-lower            Do not lowercase text: default=False\n",
      "  --min-length=MIN_LENGTH\n",
      "                        Minimum token length: default=3\n",
      "  --vocab-size=VOCAB_SIZE\n",
      "                        Size of the vocabulary (by most common, following\n",
      "                        above exclusions): default=none\n",
      "  --seed=SEED           Random integer seed (only relevant for choosing test\n",
      "                        set): default=42\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dcard/anaconda/envs/pytorch4/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2969: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import preprocess_data\n",
    "args = '-h'\n",
    "print(\"python preprocess_data.py -h\")\n",
    "preprocess_data.main([args])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we'll tell it to create a vocabulary of only 1000 words, to help the model run faster. This will select the most common 1000 words, after excluding stopwords in a standard stopword list. We'll also tell it to create the label matrices for the various metadata attributes, which we provide in a comma-separated list (without spaces). As a reminder, it will assume that each of these metadata names will be a field in each JSON document object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python preprocess_data.py tutorial/congress/train.jsonlist tutorial/congress --vocab-size 1000 --label senator,party,year,month,date\n",
      "Using snowball stopwords\n",
      "Reading data files\n",
      "Found 2483 training documents\n",
      "Found label senator with 6 classes\n",
      "Found label party with 2 classes\n",
      "Found label year with 4 classes\n",
      "Found label month with 12 classes\n",
      "Found label date with 918 classes\n",
      "Parsing 2483 documents\n",
      "Size of full vocabulary=22131\n",
      "Selecting the vocabulary\n",
      "Vocab size after filtering = 22131\n",
      "Final vocab size = 1000\n",
      "Most common words remaining: senator washington today said senate contact press also current date\n",
      "Converting to count representations\n",
      "Size of train document-term matrix: (2483, 1000)\n",
      "0 words missing from training data\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "script = 'preprocess_data.py'\n",
    "args = 'tutorial/congress/train.jsonlist tutorial/congress --vocab-size 1000 --label senator,party,year,month,date'\n",
    "print(\"python\", script, args)\n",
    "preprocess_data.main(args.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This preprocessing script creates several files, some uesd by Scholar, and some designed for other software, like Mallet. The files of interest are:\n",
    "- `train.npz`, which contains a (D x V) sparse matrix of document word counts,\n",
    "- `train.vocab.json`, which contains the vocabualry as a JSON object, and;\n",
    "- files like `train.year.csv`, which contain the year corresponding to each document, in a matrix of size (D x C), where C is the number of distinct covariate values (e.g. years)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at a couple of files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First few words in the vocbulary:\n",
      "['ability', 'able', 'abuse', 'access', 'according', 'accountability', '...']\n"
     ]
    }
   ],
   "source": [
    "# load the vocabualry\n",
    "with open(os.path.join('tutorial', 'congress', 'train.vocab.json')) as f:\n",
    "    vocab = json.load(f)\n",
    "print(\"First few words in the vocbulary:\")\n",
    "print(vocab[:6] + ['...'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start of a covariate file (train.year.csv):\n",
      "                         2005  2006  2007  2008\n",
      "10Apr2007Sanders238.txt     0     0     1     0\n",
      "10Apr2008Sanders2.txt       0     0     0     1\n",
      "10Apr2008Sanders3.txt       0     0     0     1\n",
      "10Dec2007Sanders61.txt      0     0     1     0\n",
      "10May2007Sanders212.txt     0     0     1     0\n"
     ]
    }
   ],
   "source": [
    "# load a covariate file\n",
    "import pandas as pd\n",
    "print(\"Start of a covariate file (train.year.csv):\")\n",
    "df = pd.read_csv(os.path.join('tutorial', 'congress', 'train.year.csv'), header=0, index_col=0)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that if we had a test corpus, we could simultaneously process it by adding the `--test` option to our call to `preprocess_data` (with the path to `test.jsonlist`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running Scholar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to run Scholar!\n",
    "\n",
    "To start off, let's just run a basic topic model, without any metadata. We just need to specify the input directory,  and it will look for the `train.npz` file, as well as `train.vocab.json`. \n",
    "\n",
    "Here, we'll also tell it to use 10 topics (`-k`), tell it only to run for 50 epochs (`--epochs 50`), and to use a random 1/10th of the data as a dev/validation set to monitor the fit (`--dev-folds 10`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python run_scholar.py tutorial/congress/ -k 10 --epochs 50 --dev-folds 10 --seed 99\n",
      "Loading data\n",
      "Loaded 2483 documents with 1000 features\n",
      "Found 2483 non-empty documents\n",
      "Computing background frequencies\n",
      "Min/max word counts in training data: 89 5075\n",
      "Network architecture:\n",
      "embedding_dim: 300\n",
      "n_topics: 10\n",
      "vocab_size: 1000\n",
      "label_type: None\n",
      "n_labels: 0\n",
      "n_prior_covars: 0\n",
      "n_topic_covars: 0\n",
      "l1_beta_reg: 0.0\n",
      "l1_beta_c_reg: 0.0\n",
      "l1_beta_ci_reg: 0.0\n",
      "l2_prior_reg: 0.0\n",
      "classifier_layers: 1\n",
      "use_interactions: False\n",
      "Optimizing full model\n",
      "Epoch: 10 cost= 1115.742679058\n",
      "Epoch: 10; Dev perplexity = 927.8107\n",
      "Epoch: 20 cost= 1100.415869250\n",
      "Epoch: 20; Dev perplexity = 798.8516\n",
      "Epoch: 30 cost= 1113.968918222\n",
      "Epoch: 30; Dev perplexity = 734.1056\n",
      "Epoch: 40 cost= 1098.092338681\n",
      "Epoch: 40; Dev perplexity = 716.1438\n",
      "Background frequencies of top words:\n",
      "senator obama bill said senate today washington graham press president\n",
      "[0.01305886 0.01280154 0.00948215 0.00868446 0.00810808 0.00686008\n",
      " 0.00643037 0.00634545 0.00602123 0.00594403]\n",
      "Topics:\n",
      "0: iraq states people senator lead one time also  / funds awarded assistance emergency grants carolina hickman relases ; sparsity=0.0000\n",
      "1: bill million klobuchar funding senate said projects program  / relases contact browse hickman releases graham wes date ; sparsity=0.0000\n",
      "2: barack washington statement senator contact polls newsletters alerts  / year program health percent funding billion receive national ; sparsity=0.0000\n",
      "3: court supreme people legal statement law right judge  / health provide program funding illinois million care assistance ; sparsity=0.0000\n",
      "4: obama president bill iraq spending year federal government  / relases browse releases press carolina hickman bishop graham ; sparsity=0.0010\n",
      "5: date contact press releases washington kevin wes browse  / need year act committee percent bill also congress ; sparsity=0.0000\n",
      "6: energy oil percent said americans renewable tax fuel  / browse releases press hickman bishop graham relases carolina ; sparsity=0.0000\n",
      "7: press browse record current releases mccain statement following  / obama illinois health help provide durbin care system ; sparsity=0.0000\n",
      "8: releases south press carolina graham grant wes lindsey  / american congress government legislation time people president states ; sparsity=0.0000\n",
      "9: veterans members care service health benefits returning department  / security children statement debate mccain world global vietor ; sparsity=0.0000\n",
      "sparsity in topics = 0.0001\n",
      "Dev perplexity = 697.1043\n",
      "Saving document representations\n"
     ]
    }
   ],
   "source": [
    "import run_scholar\n",
    "script = 'run_scholar.py'\n",
    "args = 'tutorial/congress/ -k 10 --epochs 50 --dev-folds 10 --seed 99'\n",
    "print(\"python\", script, args)\n",
    "run_scholar.main(args.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To display this a bit more cleanly, let's load the output and look at it.\n",
    "\n",
    "By default, the output of the model is saved to a directory called `output`, but that can be changed using the `-o` option (remember to use `-h` to see all options).\n",
    "\n",
    "First, let's inspect the background frequencies of the most common words (the log-frequencies are computed and saved)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "senator 0.013058862\n",
      "obama 0.012801543\n",
      "bill 0.009482149\n",
      "said 0.008684464\n",
      "senate 0.008108076\n",
      "today 0.006860084\n",
      "washington 0.006430366\n",
      "graham 0.006345451\n",
      "press 0.0060212314\n",
      "president 0.0059440346\n",
      "legislation 0.0057639116\n",
      "barack 0.005601804\n",
      "health 0.005578645\n",
      "million 0.005462851\n",
      "federal 0.0053933756\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "\n",
    "# load the background log-frequencies\n",
    "bg = np.load('output/bg.npz')['bg']\n",
    "\n",
    "# load the vocabualry\n",
    "with open('output/vocab.json') as f:\n",
    "    vocab = json.load(f)\n",
    "\n",
    "# sort terms by log-frequency\n",
    "order = np.argsort(bg)\n",
    "\n",
    "# print the most common words \n",
    "for i in range(1, 16):\n",
    "    index = order[-i]\n",
    "    print(vocab[index], np.exp(bg[index]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This seems like about what we would expect for the most common words, including common words, like \"said\", corpus-specific words, like \"senator\", and the names of some of the Senators we have included.\n",
    "\n",
    "Typically in topic models, we might need to remove stopwords to get good topics, but in Scholar the background term means that we don't particularly need to worry about it. (Note that the prepocessing script removed some very common words like \"the\", but they could equally have been left in).\n",
    "\n",
    "Now let's look at the topics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: iraq states people senator lead one time also ; sparsity=0.0000\n",
      "1: bill million klobuchar funding senate said projects program ; sparsity=0.0000\n",
      "2: barack washington statement senator contact polls newsletters alerts ; sparsity=0.0000\n",
      "3: court supreme people legal statement law right judge ; sparsity=0.0000\n",
      "4: obama president bill iraq spending year federal government ; sparsity=0.0010\n",
      "5: date contact press releases washington kevin wes browse ; sparsity=0.0000\n",
      "6: energy oil percent said americans renewable tax fuel ; sparsity=0.0000\n",
      "7: press browse record current releases mccain statement following ; sparsity=0.0000\n",
      "8: releases south press carolina graham grant wes lindsey ; sparsity=0.0000\n",
      "9: veterans members care service health benefits returning department ; sparsity=0.0000\n"
     ]
    }
   ],
   "source": [
    "from run_scholar import print_top_words\n",
    "\n",
    "# load the stored (K x V) topic matrix (stored in a compressed numpy format)\n",
    "beta = np.load(os.path.join('output', 'beta.npz'))['beta']\n",
    "print_top_words(beta, vocab, n_pos=8, n_neg=0);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is some order here, such as topic 9 being about the veterans, but overall these topics are not great.\n",
    "\n",
    "One problem is that we are still seeing names like \"Obama\" and \"Barack\" appearing in the topics, which is not quite what we want. To deal with this, let's add topic covariates, to introduce explicit term for each Senator, to collect the words that are more or less common overall for each one.\n",
    "\n",
    "We'll also let the model run for more epochs, to help it converge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding covariates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we introduce the `--topic-covars` option, which introduces topic-like deviations for observed one-hot covariates. Thus, in addition to the 10 topics, we will here get 6 more vectors of word weights, one for each Senator.\n",
    "\n",
    "When we add the option `--topic-covars senator`, it will look for a file called `train.senator.csv`, with one row for each document, in the same order as `train.jsonlist`. (As a reminder, this file was created by `preprocess_data.py`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python run_scholar.py tutorial/congress/ -k 10 --epochs 150 --dev-folds 10 --seed 99 --topic-covars senator\n",
      "Loading data\n",
      "Loaded 2483 documents with 1000 features\n",
      "Found 2483 non-empty documents\n",
      "Loading covariates from tutorial/congress/train.senator.csv\n",
      "Computing background frequencies\n",
      "Min/max word counts in training data: 89 5075\n",
      "Network architecture:\n",
      "embedding_dim: 300\n",
      "n_topics: 10\n",
      "vocab_size: 1000\n",
      "label_type: None\n",
      "n_labels: 0\n",
      "n_prior_covars: 0\n",
      "n_topic_covars: 6\n",
      "l1_beta_reg: 0.0\n",
      "l1_beta_c_reg: 0.0\n",
      "l1_beta_ci_reg: 0.0\n",
      "l2_prior_reg: 0.0\n",
      "classifier_layers: 1\n",
      "use_interactions: False\n",
      "Optimizing full model\n",
      "Epoch: 10 cost= 1136.829678324\n",
      "Epoch: 10; Dev perplexity = 1015.4251\n",
      "Epoch: 20 cost= 1094.823486874\n",
      "Epoch: 20; Dev perplexity = 847.3694\n",
      "Epoch: 30 cost= 1088.238418886\n",
      "Epoch: 30; Dev perplexity = 748.8656\n",
      "Epoch: 40 cost= 1053.700374458\n",
      "Epoch: 40; Dev perplexity = 658.9558\n",
      "Epoch: 50 cost= 1072.689752429\n",
      "Epoch: 50; Dev perplexity = 612.5690\n",
      "Epoch: 60 cost= 1056.849870447\n",
      "Epoch: 60; Dev perplexity = 591.6429\n",
      "Epoch: 70 cost= 1037.228435883\n",
      "Epoch: 70; Dev perplexity = 570.3315\n",
      "Epoch: 80 cost= 1055.882663940\n",
      "Epoch: 80; Dev perplexity = 550.1847\n",
      "Epoch: 90 cost= 1037.245662271\n",
      "Epoch: 90; Dev perplexity = 531.1948\n",
      "Epoch: 100 cost= 1053.812979542\n",
      "Epoch: 100; Dev perplexity = 519.0877\n",
      "Epoch: 110 cost= 1060.020574446\n",
      "Epoch: 110; Dev perplexity = 507.5692\n",
      "Epoch: 120 cost= 1074.597053272\n",
      "Epoch: 120; Dev perplexity = 489.3430\n",
      "Epoch: 130 cost= 1100.459388545\n",
      "Epoch: 130; Dev perplexity = 471.5102\n",
      "Epoch: 140 cost= 1078.030429644\n",
      "Epoch: 140; Dev perplexity = 458.2749\n",
      "Background frequencies of top words:\n",
      "senator obama bill said senate today washington graham press president\n",
      "[0.01305886 0.01280154 0.00948215 0.00868446 0.00810808 0.00686008\n",
      " 0.00643037 0.00634545 0.00602123 0.00594403]\n",
      "Topics:\n",
      "0: insurance children illegal parents immigration americans lead millions  / carolina projects iraq war appropriations project general army ; sparsity=0.0000\n",
      "1: judge nomination court justice supreme position chief attorney  / projects bill providing cost million amendment billion resources ; sparsity=0.0000\n",
      "2: statement petitions ortiz initiated electronic opinion alerts primary  / available average total cost percent amount request projects ; sparsity=0.0000\n",
      "3: defense active returning care guard armed members duty  / people interest environmental security products change united dangerous ; sparsity=0.0000\n",
      "4: energy sources gas renewable warming fuel global production  / war iraq primary determine afghanistan ask writing personal ; sparsity=0.0000\n",
      "5: announces grants training equipment grant awarded departments city  / issue united president reform bush people move call ; sparsity=0.0000\n",
      "6: budget spending earmarks fiscal priorities veto appropriations billion  / community access consumers primary individuals century announced rural ; sparsity=0.0000\n",
      "7: accountability transparency price products taxpayers companies commission financial  / home illinois war community support carolina troops families ; sparsity=0.0000\n",
      "8: infrastructure river durbin assistance recovery dick projects residents  / american war iraq reform terms military requires act ; sparsity=0.0000\n",
      "9: war iraq troops forces success political iraqi win  / million carolina projects announced bill low rural research ; sparsity=0.0000\n",
      "sparsity in topics = 0.0000\n",
      "Covariate deviations:\n",
      "Coburn: tom per coburn citizen room spending added management  / klobuchar contact wes carolina minnesota bernie kevin obama ; sparsity=0.0000\n",
      "Graham: carolina graham wes lindsey south kevin bishop relases  / klobuchar minnesota obama immediate initiated barack green sanders ; sparsity=0.0000\n",
      "Klobuchar: minnesota klobuchar commerce amy cities rural farmers transportation  / graham contact kevin obama gibbs press ortiz barack ; sparsity=0.0000\n",
      "McCain: mccain john browse current air record remains though  / alerts contact vietor ben barack ortiz wes kevin ; sparsity=0.0000\n",
      "Obama: illinois newsletters tommy alerts julian ortiz polls pursuant  / graham carolina wes klobuchar press releases browse south ; sparsity=0.0000\n",
      "Sanders: sanders sen warming bernie bush http global read  / minnesota contact carolina alerts barack obama immediate south ; sparsity=0.0000\n",
      "sparsity in covariates = 0.0000\n",
      "Dev perplexity = 449.3771\n",
      "Saving document representations\n"
     ]
    }
   ],
   "source": [
    "script = 'run_scholar.py'\n",
    "args = 'tutorial/congress/ -k 10 --epochs 150 --dev-folds 10 --seed 99 --topic-covars senator'\n",
    "print(\"python\", script, args)\n",
    "run_scholar.main(args.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, let's load the topics and have a look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: insurance children illegal parents immigration americans lead millions ; sparsity=0.0000\n",
      "1: judge nomination court justice supreme position chief attorney ; sparsity=0.0000\n",
      "2: statement petitions ortiz initiated electronic opinion alerts primary ; sparsity=0.0000\n",
      "3: defense active returning care guard armed members duty ; sparsity=0.0000\n",
      "4: energy sources gas renewable warming fuel global production ; sparsity=0.0000\n",
      "5: announces grants training equipment grant awarded departments city ; sparsity=0.0000\n",
      "6: budget spending earmarks fiscal priorities veto appropriations billion ; sparsity=0.0000\n",
      "7: accountability transparency price products taxpayers companies commission financial ; sparsity=0.0000\n",
      "8: infrastructure river durbin assistance recovery dick projects residents ; sparsity=0.0000\n",
      "9: war iraq troops forces success political iraqi win ; sparsity=0.0000\n"
     ]
    }
   ],
   "source": [
    "beta = np.load('output/beta.npz')['beta']\n",
    "print_top_words(beta, vocab, n_pos=8, n_neg=0);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These look much better! Depending on the run, there are fairly clear topics for the supreme court, budgets, the Iraq war, and so on.\n",
    "\n",
    "In addition, we can load the vectors that have been learned for each Senator, which will be saved in a file called `beta_c.npz`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coburn: tom per coburn citizen room spending added management subcommittee dollars ; sparsity=0.0000\n",
      "Graham: carolina graham wes lindsey south kevin bishop relases releases hickman ; sparsity=0.0000\n",
      "Klobuchar: minnesota klobuchar commerce amy cities rural farmers transportation consumers serves ; sparsity=0.0000\n",
      "McCain: mccain john browse current air record remains though success colleagues ; sparsity=0.0000\n",
      "Obama: illinois newsletters tommy alerts julian ortiz polls pursuant barack obama ; sparsity=0.0000\n",
      "Sanders: sanders sen warming bernie bush http global read added middle ; sparsity=0.0000\n"
     ]
    }
   ],
   "source": [
    "topic_covars = np.load(os.path.join('output', 'beta_c.npz'))\n",
    "weights = topic_covars['beta']\n",
    "names = topic_covars['names']\n",
    "print_top_words(weights, vocab, topic_names=names, n_pos=10, n_neg=0);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are clearly about right, in that the Senator's names and/or states are appearing in the right vectors. It is hard to make sense of some of these, but they appear to doing the right thing in terms of pulling the Senator-specific terms out of the topics.\n",
    "\n",
    "Note that if we had used the full dataset, we could easily extend the covariates to include a variable for each Senator without difficulty, which would be quite slow to run in the structural topic model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing results\n",
    "\n",
    "Let's load the resulting document-topic proportions for the training data, and look a random example. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10Apr2008Sanders2.txt\n",
      "SENATE ADOPTS SANDERS VETERANS PROVISION IN HOUSING BILL   The Senate today put finishing touches on housing stimulus legislation, adding a $57 million proposal authored by Senator Bernie Sanders (I-Vt.) that would increase federal grants to help disabled veterans adapt their homes.     \"With so many soldiers coming back from Iraq with disabilities, it is absolutely imperative that we make sure they have as normal a life as possible and that certainly includes adapting their homes to meet their needs,\" Sanders said.    The final bill, which the Senate approved 84 to 12, also included energy tax credits cosponsored by Sanders that would promote renewable energy and energy efficiency. It would extend expiring federal tax benefits for investment in solar, wind and other sustainable energy sources.    Sanders also was the lead cosponsor of a successful amendment by Senator Patrick Leahy (D-Vt.) that would guarantee Vermont a $20 million share of $4 billion in community development block grants to prevent home foreclosures and to refurbish abandoned homes.    Under the veterans amendment, veterans with certain severe service-connected disabilities would be eligible for grants of up to $60,000, a $10,000 boost from the current law, to build wheelchair ramps and to make other changes so they could live at home. Veterans who were blinded or lost arms in war zones or while on active duty may receive up to $12,000, a $2,000 increase, for remodeling their homes.    The amendment also would provide for automatic annual adjustments pegged to a home construction cost index to ensure that the benefits keep pace with rising prices. Wounded veterans returning from Iraq and Afghanistan have found that the program now on the books does not cover all of the costs of adapting their homes.    Sanders' amendment was supported by the American Legion, Veterans of Foreign Wars, Disabled American Veterans, Vietnam Veterans of America, AMVETS, Paralyzed Veterans of America and others.    Before passing the bill, the Senate also added the energy provisions. \"There are huge opportunities that we will lose if we do not extend these sustainable energy tax credits,\" Sanders said. \"Not only will these tax credits enable us to continue our effort to break our dependency on the fossil fuels that cause global warming and pollute our environment, but they will provide a significant number of good-paying green jobs in the areas of wind, solar and geothermal - something that I am working very hard on and believe has tremendous potential for our economy.\"    The Leahy-Sanders Amendment would allot $20 million to help Vermont deal with the foreclosure crisis that is sweeping the country. \"With this funding, it is my hope that Vermont's cities and towns will be able to provide immediate assistance to the struggling middle class trying to hold onto their homes and improve communities hit hard by foreclosures,\" Sanders said. \"Clearly, we must do everything we can to prevent the American dream of homeownership from turning into the American nightmare of foreclosure that too many American families are experiencing.\"    \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# load the matrix with topic proportions for each document (note that this excludes those in the dev set).\n",
    "npz = np.load(os.path.join('output', 'theta.train.npz')) \n",
    "ids = npz['ids']\n",
    "theta = npz['theta']\n",
    "n_docs, n_topics = theta.shape\n",
    "\n",
    "index = 1\n",
    "# plot the proportion of each topic in the first document\n",
    "fig, ax = plt.subplots()\n",
    "ax.bar(range(n_topics), theta[index, :])\n",
    "\n",
    "# find the original line corresponding to this document, and display the text\n",
    "print(ids[index])\n",
    "for line in lines:\n",
    "    doc = json.loads(line)\n",
    "    if doc['id'] == ids[index]:\n",
    "        print(doc['text'])\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This seems about right! The press release is mostly about returning veterans (topic 3), but also about energy policy (topic 4), with some words from infrastructure mixed in (topic 8)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's plot the relative prevalance of each topics for each Senator.\n",
    "\n",
    "Because scholar split the training data into a training set and a dev set, we need to match up the output to the original senator variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# load the senator variable for all the documents\n",
    "senators_df = pd.read_csv(os.path.join('tutorial', 'congress', 'train.senator.csv'), header=0, index_col=0)\n",
    "senators = senators_df.columns\n",
    "\n",
    "# pull out a subset corresponding to the ids from above\n",
    "train_subset = senators_df.loc[ids]\n",
    "n_docs, n_senators = train_subset.shape\n",
    "\n",
    "# plot the average senator-topic proportions\n",
    "fig, ax = plt.subplots()\n",
    "lefts = np.zeros(n_senators)\n",
    "for k in range(n_topics):\n",
    "    vals = []\n",
    "    for senator in senators:\n",
    "        vals.append(np.mean(theta[train_subset[senator] == 1, k]))\n",
    "\n",
    "    ax.barh(range(n_senators), vals, left=lefts)\n",
    "    lefts += np.array(vals)\n",
    "    \n",
    "ax.set_yticks(range(n_senators))\n",
    "ax.set_yticklabels(senators)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This seems to have at least some face validity, with Bernie Sanders writing the most about social issues (topic 0), and Amy Klobuchar writing more about energy/environmental issues (topic 4), but more expertise would be useful in exploring this further. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing with pretrained word vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Emperically, we found that initializing the model with pretrained word vectors led to greater coherence in the topics. If you are interested in trying this, it is necessary to download the pretrained word2vec vectors from https://drive.google.com/file/d/0B7XkCwpI5KDYNlNUTTlSS21pQmM/edit?usp=sharing\n",
    "\n",
    "Once this is done, and these have been saved somewhere, we can add the `--w2v` option to the model, with a path to the vector file. Here, we'll assume it's in the local directory.\n",
    "\n",
    "Note that it takes some time to load the word vectors, so we'll just try this once for illustration purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python run_scholar.py tutorial/congress/ -k 10 --epochs 150 --dev-folds 10 --seed 99 --topic-covars senator --w2v ./vectors/GoogleNews-vectors-negative300.bin\n",
      "Loading data\n",
      "Loaded 2483 documents with 1000 features\n",
      "Found 2483 non-empty documents\n",
      "Loading covariates from tutorial/congress/train.senator.csv\n",
      "Computing background frequencies\n",
      "Min/max word counts in training data: 89 5075\n",
      "Network architecture:\n",
      "embedding_dim: 300\n",
      "n_topics: 10\n",
      "vocab_size: 1000\n",
      "label_type: None\n",
      "n_labels: 0\n",
      "n_prior_covars: 0\n",
      "n_topic_covars: 6\n",
      "l1_beta_reg: 0.0\n",
      "l1_beta_c_reg: 0.0\n",
      "l1_beta_ci_reg: 0.0\n",
      "l2_prior_reg: 0.0\n",
      "classifier_layers: 1\n",
      "use_interactions: False\n",
      "Loading word vectors\n",
      "Found embeddings for 991 words\n",
      "Optimizing full model\n",
      "Epoch: 10 cost= 1138.788166772\n",
      "Epoch: 10; Dev perplexity = 840.7113\n",
      "Epoch: 20 cost= 1070.779092605\n",
      "Epoch: 20; Dev perplexity = 690.3290\n",
      "Epoch: 30 cost= 1115.120284317\n",
      "Epoch: 30; Dev perplexity = 625.7116\n",
      "Epoch: 40 cost= 1102.541214433\n",
      "Epoch: 40; Dev perplexity = 591.7534\n",
      "Epoch: 50 cost= 1055.403973539\n",
      "Epoch: 50; Dev perplexity = 573.7500\n",
      "Epoch: 60 cost= 1051.020578815\n",
      "Epoch: 60; Dev perplexity = 558.4173\n",
      "Epoch: 70 cost= 1044.111797836\n",
      "Epoch: 70; Dev perplexity = 543.1413\n",
      "Epoch: 80 cost= 1067.667020589\n",
      "Epoch: 80; Dev perplexity = 530.6057\n",
      "Epoch: 90 cost= 1065.176966452\n",
      "Epoch: 90; Dev perplexity = 522.1218\n",
      "Epoch: 100 cost= 1086.810403777\n",
      "Epoch: 100; Dev perplexity = 513.6387\n",
      "Epoch: 110 cost= 1059.577844266\n",
      "Epoch: 110; Dev perplexity = 508.6303\n",
      "Epoch: 120 cost= 1074.292434590\n",
      "Epoch: 120; Dev perplexity = 496.3905\n",
      "Epoch: 130 cost= 1052.196462746\n",
      "Epoch: 130; Dev perplexity = 482.6712\n",
      "Epoch: 140 cost= 1059.480832503\n",
      "Epoch: 140; Dev perplexity = 471.0872\n",
      "Background frequencies of top words:\n",
      "senator obama bill said senate today washington graham press president\n",
      "[0.01305886 0.01280154 0.00948215 0.00868446 0.00810808 0.00686008\n",
      " 0.00643037 0.00634545 0.00602123 0.00594403]\n",
      "Topics:\n",
      "0: iraq statement troops released war win following democratic  / receive program federal durbin percent illinois facilities low ; sparsity=0.0000\n",
      "1: consumer illegal immigration border commission reform products information  / war assistance sacrifice illinois army military iraq served ; sparsity=0.0000\n",
      "2: departments grants project fire receive equipment announce funds  / right policies statement long issue longer people democratic ; sparsity=0.0000\n",
      "3: statement press released announced announces browse following lindsey  / military bill war iraq troops back members defense ; sparsity=0.0000\n",
      "4: energy renewable gas global oil sources vehicles incentives  / serving services ask military department certain receive kevin ; sparsity=0.0000\n",
      "5: court judge supreme justice values decisions chief respect  / receive billion awarded providing increase rural fiscal families ; sparsity=0.0000\n",
      "6: assistance affected counties recovery residents dick disaster delegation  / war military requires bill legislation better iraq troops ; sparsity=0.0000\n",
      "7: fiscal billion budget tax appropriations spending priorities earmarks  / kevin potential general dangerous independence releases sincerely letter ; sparsity=0.0000\n",
      "8: guard care veterans returning members service health medical  / statement energy kevin independence economy foreign economic politics ; sparsity=0.0000\n",
      "9: iraq course back troops forces strategy war illegal  / federal department awarded receive contact departments kevin programs ; sparsity=0.0000\n",
      "sparsity in topics = 0.0000\n",
      "Covariate deviations:\n",
      "Coburn: room citizen coburn tom per spending released amendments  / date petitions bishop thursday contact browse obama south ; sparsity=0.0000\n",
      "Graham: kevin wes awarded relases releases hickman demint bishop  / durbin illinois immediate release thursday vietor sanders special ; sparsity=0.0000\n",
      "Klobuchar: minnesota klobuchar consumer consumers serves commerce products amy  / date kevin obama illinois press polls barack coburn ; sparsity=0.0000\n",
      "McCain: mccain browse john record land current legislative freedom  / contact kevin durbin illinois barack petitions wes newsletters ; sparsity=0.0000\n",
      "Obama: immediate labolt obama polls illinois petitions julian durbin  / wes minnesota press kevin graham bishop lindsey south ; sparsity=0.0010\n",
      "Sanders: sanders vermont bernie http read told sen worse  / date obama kevin ben lindsey immediate newsletters washington ; sparsity=0.0000\n",
      "sparsity in covariates = 0.0002\n",
      "Dev perplexity = 463.4898\n",
      "Saving document representations\n"
     ]
    }
   ],
   "source": [
    "script = 'run_scholar.py'\n",
    "args = 'tutorial/congress/ -k 10 --epochs 150 --dev-folds 10 --seed 99 --topic-covars senator --w2v ./vectors/GoogleNews-vectors-negative300.bin'\n",
    "print(\"python\", script, args)\n",
    "run_scholar.main(args.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: iraq statement troops released war win following democratic ; sparsity=0.0000\n",
      "1: consumer illegal immigration border commission reform products information ; sparsity=0.0000\n",
      "2: departments grants project fire receive equipment announce funds ; sparsity=0.0000\n",
      "3: statement press released announced announces browse following lindsey ; sparsity=0.0000\n",
      "4: energy renewable gas global oil sources vehicles incentives ; sparsity=0.0000\n",
      "5: court judge supreme justice values decisions chief respect ; sparsity=0.0000\n",
      "6: assistance affected counties recovery residents dick disaster delegation ; sparsity=0.0000\n",
      "7: fiscal billion budget tax appropriations spending priorities earmarks ; sparsity=0.0000\n",
      "8: guard care veterans returning members service health medical ; sparsity=0.0000\n",
      "9: iraq course back troops forces strategy war illegal ; sparsity=0.0000\n"
     ]
    }
   ],
   "source": [
    "beta = np.load('output/beta.npz')['beta']\n",
    "print_top_words(beta, vocab, n_pos=8, n_neg=0);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, the results seem quite similar, but it might be more beneficial when working with a larger vocabualry (and therefore words which occur less frequently)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding more covariates\n",
    "\n",
    "Note that we can easily include additional covarites in the same way as we did for senators. Let's try also including covariates for year and month. Just include them in a comma-separated list (again, without spaces)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python run_scholar.py tutorial/congress/ -k 10 --epochs 150 --dev-folds 10 --seed 99 --topic-covars senator,year,month\n",
      "Loading data\n",
      "Loaded 2483 documents with 1000 features\n",
      "Found 2483 non-empty documents\n",
      "Loading covariates from tutorial/congress/train.senator.csv\n",
      "Loading covariates from tutorial/congress/train.year.csv\n",
      "Loading covariates from tutorial/congress/train.month.csv\n",
      "Computing background frequencies\n",
      "Min/max word counts in training data: 89 5075\n",
      "Network architecture:\n",
      "embedding_dim: 300\n",
      "n_topics: 10\n",
      "vocab_size: 1000\n",
      "label_type: None\n",
      "n_labels: 0\n",
      "n_prior_covars: 0\n",
      "n_topic_covars: 22\n",
      "l1_beta_reg: 0.0\n",
      "l1_beta_c_reg: 0.0\n",
      "l1_beta_ci_reg: 0.0\n",
      "l2_prior_reg: 0.0\n",
      "classifier_layers: 1\n",
      "use_interactions: False\n",
      "Optimizing full model\n",
      "Epoch: 10 cost= 1116.675995351\n",
      "Epoch: 10; Dev perplexity = 882.6570\n",
      "Epoch: 20 cost= 1078.618546386\n",
      "Epoch: 20; Dev perplexity = 764.7248\n",
      "Epoch: 30 cost= 1073.322633748\n",
      "Epoch: 30; Dev perplexity = 677.8801\n",
      "Epoch: 40 cost= 1041.660238176\n",
      "Epoch: 40; Dev perplexity = 644.9560\n",
      "Epoch: 50 cost= 1061.772925187\n",
      "Epoch: 50; Dev perplexity = 620.3085\n",
      "Epoch: 60 cost= 1046.160847709\n",
      "Epoch: 60; Dev perplexity = 592.2704\n",
      "Epoch: 70 cost= 1027.448222525\n",
      "Epoch: 70; Dev perplexity = 562.8738\n",
      "Epoch: 80 cost= 1045.999305264\n",
      "Epoch: 80; Dev perplexity = 542.9608\n",
      "Epoch: 90 cost= 1026.946248645\n",
      "Epoch: 90; Dev perplexity = 523.0195\n",
      "Epoch: 100 cost= 1045.108475994\n",
      "Epoch: 100; Dev perplexity = 504.4045\n",
      "Epoch: 110 cost= 1050.734366261\n",
      "Epoch: 110; Dev perplexity = 491.4653\n",
      "Epoch: 120 cost= 1064.437285899\n",
      "Epoch: 120; Dev perplexity = 469.6090\n",
      "Epoch: 130 cost= 1087.231609165\n",
      "Epoch: 130; Dev perplexity = 451.5761\n",
      "Epoch: 140 cost= 1064.638437019\n",
      "Epoch: 140; Dev perplexity = 439.3306\n",
      "Background frequencies of top words:\n",
      "senator obama bill said senate today washington graham press president\n",
      "[0.01305886 0.01280154 0.00948215 0.00868446 0.00810808 0.00686008\n",
      " 0.00643037 0.00634545 0.00602123 0.00594403]\n",
      "Topics:\n",
      "0: immigration products lead illegal laws parents think say  / funds carolina awarded receive community rural grants programs ; sparsity=0.0000\n",
      "1: judge nomination supreme court justice attorney position chief  / funding funds billion million resources program fiscal troops ; sparsity=0.0000\n",
      "2: transparency accountability taxpayers management agency agencies spent house  / care health children receive policies iraq war insurance ; sparsity=0.0000\n",
      "3: development announces project transportation improvements research projects county  / country american political iraq americans government know issue ; sparsity=0.0000\n",
      "4: grants awarded equipment share departments local announce grant  / change leadership called military war senate care reform ; sparsity=0.0000\n",
      "5: global climate gas renewable warming sources energy reduce  / health services iraq veterans war armed children troops ; sparsity=0.0000\n",
      "6: statement released following democracy democratic freedom passing world  / department based provide federal related year letter according ; sparsity=0.0000\n",
      "7: iraq soldiers troops war iraqi forces armed military  / federal businesses children insurance reform industry million business ; sparsity=0.0000\n",
      "8: care health centers veterans insurance services quality medical  / change security iraq transparency responsibility political course interests ; sparsity=0.0000\n",
      "9: tax spending fiscal billion families income budget debt  / letter united releases international agency security east officials ; sparsity=0.0000\n",
      "sparsity in topics = 0.0000\n",
      "Covariate deviations:\n",
      "Coburn: citizen coburn per room tom released earmarks transparency  / releases graham carolina kevin tommy sanders hickman obama ; sparsity=0.0000\n",
      "Graham: wes releases graham carolina browse hickman kevin lindsey  / obama barack thursday gibbs immediate julian tommy klobuchar ; sparsity=0.0000\n",
      "Klobuchar: klobuchar minnesota secured consumer commerce serves beyond guard  / barack polls date graham wes immediate newsletters ortiz ; sparsity=0.0000\n",
      "McCain: mccain browse freedom john record success simply greater  / carolina klobuchar graham obama kevin tommy hickman thursday ; sparsity=0.0000\n",
      "Obama: barack release immediate illinois julian obama gibbs contact  / wes klobuchar press releases carolina graham kevin sanders ; sparsity=0.0000\n",
      "Sanders: sanders bernie http read sen vermont warming bush  / graham amy wes carolina ben date labolt polls ; sparsity=0.0000\n",
      "2005: julian tommy vietor green robert gibbs announces south  / amy newsletters ortiz initiated pursuant alerts electronic opinion ; sparsity=0.0000\n",
      "2006: tommy vietor gibbs julian robert announce terrorists green  / ortiz petitions newsletters initiated opinion alerts polls pursuant ; sparsity=0.0000\n",
      "2007: labolt ben brundage farmers farm sanders consequences http  / gibbs vietor tommy julian ortiz robert opinion newsletters ; sparsity=0.0000\n",
      "2008: petitions polls alerts pursuant newsletters ortiz initiated michael  / gibbs vietor tommy ben julian labolt brundage carolina ; sparsity=0.0000\n",
      "Apr: april location price temporary prices drug abuse calls  / june july september brundage august terror complete quickly ; sparsity=0.0000\n",
      "Aug: august transportation announce letter damage receive office area  / rates union brundage finally expected decades allowing polls ; sparsity=0.0000\n",
      "Dec: december newsletters petitions polls initiated electronic opinion alerts  / ben labolt third advance something june april supporting ; sparsity=0.0000\n",
      "Feb: february cut eliminate bipartisan receiving amendments debate proposal  / july april along august september brundage small line ; sparsity=0.0000\n",
      "Jan: january things decisions sources economic agree warming legislative  / july april september estimated location october june march ; sparsity=0.0000\n",
      "Jul: july ways strengthen moving debt governments hearing ben  / october brundage november april september location respond union ; sparsity=0.0000\n",
      "Jun: june immigration choice worse businesses offered countries standard  / brundage october march july ensuring august amy september ; sparsity=0.0000\n",
      "Mar: march budget alone conditions paid billions resolution increases  / july june brundage october september august opportunities signed ; sparsity=0.0000\n",
      "May: immigration committed takes comprehensive defense reforms pay workers  / july october terrorists follow brundage amy effective september ; sparsity=0.0000\n",
      "Nov: november petitions newsletters initiated amy polls brundage period  / ben july labolt march noted june insurance establish ; sparsity=0.0000\n",
      "Oct: october amy brundage reported human specifically private values  / labolt often july designed march man leaders met ; sparsity=0.0000\n",
      "Sep: september chief amy ahead general month recovery view  / july november march ben initiated january june labolt ; sparsity=0.0000\n",
      "sparsity in covariates = 0.0000\n",
      "Dev perplexity = 431.7210\n",
      "Saving document representations\n"
     ]
    }
   ],
   "source": [
    "script = 'run_scholar.py'\n",
    "args = 'tutorial/congress/ -k 10 --epochs 150 --dev-folds 10 --seed 99 --topic-covars senator,year,month'\n",
    "print(\"python\", script, args)\n",
    "run_scholar.main(args.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now if we load the covariate vectors, we will also see some temporal patterns in word frequencies. The ones here don't seem all that compelling, but perhaps more data is needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coburn: citizen coburn per room tom released earmarks transparency ; sparsity=0.0000\n",
      "Graham: wes releases graham carolina browse hickman kevin lindsey ; sparsity=0.0000\n",
      "Klobuchar: klobuchar minnesota secured consumer commerce serves beyond guard ; sparsity=0.0000\n",
      "McCain: mccain browse freedom john record success simply greater ; sparsity=0.0000\n",
      "Obama: barack release immediate illinois julian obama gibbs contact ; sparsity=0.0000\n",
      "Sanders: sanders bernie http read sen vermont warming bush ; sparsity=0.0000\n",
      "2005: julian tommy vietor green robert gibbs announces south ; sparsity=0.0000\n",
      "2006: tommy vietor gibbs julian robert announce terrorists green ; sparsity=0.0000\n",
      "2007: labolt ben brundage farmers farm sanders consequences http ; sparsity=0.0000\n",
      "2008: petitions polls alerts pursuant newsletters ortiz initiated michael ; sparsity=0.0000\n",
      "Apr: april location price temporary prices drug abuse calls ; sparsity=0.0000\n",
      "Aug: august transportation announce letter damage receive office area ; sparsity=0.0000\n",
      "Dec: december newsletters petitions polls initiated electronic opinion alerts ; sparsity=0.0000\n",
      "Feb: february cut eliminate bipartisan receiving amendments debate proposal ; sparsity=0.0000\n",
      "Jan: january things decisions sources economic agree warming legislative ; sparsity=0.0000\n",
      "Jul: july ways strengthen moving debt governments hearing ben ; sparsity=0.0000\n",
      "Jun: june immigration choice worse businesses offered countries standard ; sparsity=0.0000\n",
      "Mar: march budget alone conditions paid billions resolution increases ; sparsity=0.0000\n",
      "May: immigration committed takes comprehensive defense reforms pay workers ; sparsity=0.0000\n",
      "Nov: november petitions newsletters initiated amy polls brundage period ; sparsity=0.0000\n",
      "Oct: october amy brundage reported human specifically private values ; sparsity=0.0000\n",
      "Sep: september chief amy ahead general month recovery view ; sparsity=0.0000\n"
     ]
    }
   ],
   "source": [
    "topic_covars = np.load(os.path.join('output', 'beta_c.npz'))\n",
    "weights = topic_covars['beta']\n",
    "names = topic_covars['names']\n",
    "print_top_words(weights, vocab, topic_names=names, n_pos=8, n_neg=0);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactions\n",
    "\n",
    "Alternatively, we can include interactions between covariates and topics.\n",
    "\n",
    "Here, let's try using a covariate for party membership, rather than for each Senator, and include interactions between topics and party. To do this, just include the `--interactions` options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python run_scholar.py tutorial/congress/ -k 10 --epochs 200 --dev-folds 10 --seed 99 --topic-covars party --interactions\n",
      "Loading data\n",
      "Loaded 2483 documents with 1000 features\n",
      "Found 2483 non-empty documents\n",
      "Loading covariates from tutorial/congress/train.party.csv\n",
      "Computing background frequencies\n",
      "Min/max word counts in training data: 89 5075\n",
      "Network architecture:\n",
      "embedding_dim: 300\n",
      "n_topics: 10\n",
      "vocab_size: 1000\n",
      "label_type: None\n",
      "n_labels: 0\n",
      "n_prior_covars: 0\n",
      "n_topic_covars: 2\n",
      "l1_beta_reg: 0.0\n",
      "l1_beta_c_reg: 0.0\n",
      "l1_beta_ci_reg: 0.0\n",
      "l2_prior_reg: 0.0\n",
      "classifier_layers: 1\n",
      "use_interactions: True\n",
      "Optimizing full model\n",
      "Epoch: 10 cost= 1144.967152982\n",
      "Epoch: 10; Dev perplexity = 1011.0764\n",
      "Epoch: 20 cost= 1103.227287822\n",
      "Epoch: 20; Dev perplexity = 964.6040\n",
      "Epoch: 30 cost= 1097.839415548\n",
      "Epoch: 30; Dev perplexity = 814.4726\n",
      "Epoch: 40 cost= 1063.225387129\n",
      "Epoch: 40; Dev perplexity = 710.2364\n",
      "Epoch: 50 cost= 1081.885306339\n",
      "Epoch: 50; Dev perplexity = 678.7429\n",
      "Epoch: 60 cost= 1063.214185062\n",
      "Epoch: 60; Dev perplexity = 653.2096\n",
      "Epoch: 70 cost= 1039.975307388\n",
      "Epoch: 70; Dev perplexity = 637.7933\n",
      "Epoch: 80 cost= 1059.151526671\n",
      "Epoch: 80; Dev perplexity = 614.1905\n",
      "Epoch: 90 cost= 1037.097151583\n",
      "Epoch: 90; Dev perplexity = 594.5338\n",
      "Epoch: 100 cost= 1051.983918397\n",
      "Epoch: 100; Dev perplexity = 571.4534\n",
      "Epoch: 110 cost= 1054.278643649\n",
      "Epoch: 110; Dev perplexity = 556.0418\n",
      "Epoch: 120 cost= 1073.586928263\n",
      "Epoch: 120; Dev perplexity = 536.7647\n",
      "Epoch: 130 cost= 1105.235751363\n",
      "Epoch: 130; Dev perplexity = 524.4831\n",
      "Epoch: 140 cost= 1087.903645833\n",
      "Epoch: 140; Dev perplexity = 509.4288\n",
      "Epoch: 150 cost= 1072.530913556\n",
      "Epoch: 150; Dev perplexity = 498.4460\n",
      "Epoch: 160 cost= 1066.400329453\n",
      "Epoch: 160; Dev perplexity = 481.6578\n",
      "Epoch: 170 cost= 1071.905574927\n",
      "Epoch: 170; Dev perplexity = 468.4864\n",
      "Epoch: 180 cost= 1091.065206848\n",
      "Epoch: 180; Dev perplexity = 459.1624\n",
      "Epoch: 190 cost= 1040.076098687\n",
      "Epoch: 190; Dev perplexity = 451.6792\n",
      "Background frequencies of top words:\n",
      "senator obama bill said senate today washington graham press president\n",
      "[0.01305886 0.01280154 0.00948215 0.00868446 0.00810808 0.00686008\n",
      " 0.00643037 0.00634545 0.00602123 0.00594403]\n",
      "Topics:\n",
      "0: duty insurance active men care members service families  / dick tommy water vietor used relases green gibbs ; sparsity=0.0000\n",
      "1: fire grants awarded tools dick purchase assistance sincerely  / minnesota helped political mccain klobuchar reform elected debate ; sparsity=0.0000\n",
      "2: consumers mccain choice hearing market commerce industry consumer  / immediate barack initiated newsletters electronic date obama troops ; sparsity=0.0000\n",
      "3: carolina announces south bishop wes announced investment relases  / sanders vermont mccain coburn personnel days many citizen ; sparsity=0.0000\n",
      "4: earmarks recovery spending coburn dollars room taxpayers congress  / hickman relases lindsey graham contact kevin wes bishop ; sparsity=0.0000\n",
      "5: immigration renewable oil fuel energy fuels illegal economy  / alerts initiated conduct newsletters primary ortiz brave opinion ; sparsity=0.0000\n",
      "6: projects defense funding construction project million research secured  / political middle want reform people debate hickman relases ; sparsity=0.0000\n",
      "7: statement released nomination following passing julian release alerts  / minnesota klobuchar number dollars problem projects percent additional ; sparsity=0.0000\n",
      "8: sanders warming court http change votes things global  / julian payments barack immediate programs million grants obama ; sparsity=0.0000\n",
      "9: iraq iraqi general violence political strategy security accountability  / vermont minnesota klobuchar sanders hickman million lindsey bernie ; sparsity=0.0010\n",
      "sparsity in topics = 0.0001\n",
      "Covariate deviations:\n",
      "D: immediate vietor minnesota labolt damage veterans farmers vermont  / releases lindsey hickman kevin carolina browse bishop south ; sparsity=0.0000\n",
      "R: relases hickman departments record current lindsey releases freedom  / barack amy klobuchar alerts initiated vermont julian pursuant ; sparsity=0.0000\n",
      "sparsity in covariates = 0.0000\n",
      "Covariate interactions\n",
      "(20, 1000)\n",
      "0:D: served service sanders returning soldiers veterans members insurance  / dick consideration releases criminal control hickman opinion mccain ; sparsity=0.0000\n",
      "0:R: freedom always choice individuals greater control social rates  / sanders amy labolt barack bernie director used vermont ; sparsity=0.0000\n",
      "1:D: dick durbin dear request sincerely counties assistance letter  / hickman relases demint bishop brave investment minnesota middle ; sparsity=0.0000\n",
      "1:R: announce fire grants awarded demint equipment announces personnel  / dear even dick legislation last government amy upon ; sparsity=0.0000\n",
      "2:D: klobuchar consumers consumer drug prices industry commerce companies  / date contact alerts initiated barack mccain hickman relases ; sparsity=0.0000\n",
      "2:R: mccain john choice power browse legislation regarding commitment  / klobuchar minnesota sanders insurance fiscal troops projects million ; sparsity=0.0000\n",
      "3:D: bill reform products klobuchar farm consumer safety commission  / record hickman lindsey relases sanders vermont news department ; sparsity=0.0000\n",
      "3:R: announces wes kevin bishop hickman carolina demint south  / far citizen electronic barack amy klobuchar opinion just ; sparsity=0.0000\n",
      "4:D: assistance recovery relief income counties quickly local residents  / green labolt press hickman debate earmarks citizen policy ; sparsity=0.0000\n",
      "4:R: earmarks room coburn spending per bills congress transparency  / hickman contact date relases kevin amy wes lindsey ; sparsity=0.0000\n",
      "5:D: fuels fuel oil renewable energy economy independence vehicles  / hickman electronic relases kevin releases graham members initiated ; sparsity=0.0000\n",
      "5:R: immigration border illegal reform security temporary secure comprehensive  / sanders tommy ever bernie gibbs wednesday vermont friday ; sparsity=0.0000\n",
      "6:D: illinois funding project secured river serve successful construction  / coburn debate rules politics reform press now middle ; sparsity=0.0000\n",
      "6:R: armed million authorization air changes almost goes purchase  / amy labolt barack contact dick minnesota durbin chance ; sparsity=0.0000\n",
      "7:D: electronic initiated alerts newsletters julian petitions obama pursuant  / current releases hickman minnesota lindsey klobuchar relases mccain ; sparsity=0.0000\n",
      "7:R: kevin browse experience john lindsey man mccain court  / control sure already issue approved required close provide ; sparsity=0.0000\n",
      "8:D: warming sanders troops reducing global challenge climate political  / contact hickman tommy vietor lindsey durbin releases gibbs ; sparsity=0.0000\n",
      "8:R: court supreme judge votes trying legal want fair  / sanders bernie amy reducing labolt announced help grants ; sparsity=0.0000\n",
      "9:D: accountability dear obama security reports gibbs brundage conduct  / vermont sanders minnesota klobuchar hickman middle floor families ; sparsity=0.0000\n",
      "9:R: middle iraq troops mission iraqi sacrifice send getting  / contact gibbs tommy barack vietor newsletters amy labolt ; sparsity=0.0000\n",
      "sparsity in covariate interactions = 0.0000\n",
      "Dev perplexity = 446.5785\n",
      "Saving document representations\n"
     ]
    }
   ],
   "source": [
    "script = 'run_scholar.py'\n",
    "args = 'tutorial/congress/ -k 10 --epochs 200 --dev-folds 10 --seed 99 --topic-covars party --interactions'\n",
    "print(\"python\", script, args)\n",
    "run_scholar.main(args.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's look at the vectors learned for each party, then the topics, then the interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D: immediate vietor minnesota labolt damage veterans farmers vermont ; sparsity=0.0000\n",
      "R: relases hickman departments record current lindsey releases freedom ; sparsity=0.0000\n"
     ]
    }
   ],
   "source": [
    "topic_covars = np.load(os.path.join('output', 'beta_c.npz'))\n",
    "weights = topic_covars['beta']\n",
    "names = topic_covars['names']\n",
    "print_top_words(weights, vocab, topic_names=names, n_pos=8, n_neg=0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: duty insurance active men care members service families ; sparsity=0.0000\n",
      "1: fire grants awarded tools dick purchase assistance sincerely ; sparsity=0.0000\n",
      "2: consumers mccain choice hearing market commerce industry consumer ; sparsity=0.0000\n",
      "3: carolina announces south bishop wes announced investment relases ; sparsity=0.0000\n",
      "4: earmarks recovery spending coburn dollars room taxpayers congress ; sparsity=0.0000\n",
      "5: immigration renewable oil fuel energy fuels illegal economy ; sparsity=0.0000\n",
      "6: projects defense funding construction project million research secured ; sparsity=0.0000\n",
      "7: statement released nomination following passing julian release alerts ; sparsity=0.0000\n",
      "8: sanders warming court http change votes things global ; sparsity=0.0000\n",
      "9: iraq iraqi general violence political strategy security accountability ; sparsity=0.0010\n"
     ]
    }
   ],
   "source": [
    "beta = np.load(os.path.join('output', 'beta.npz'))['beta']\n",
    "print_top_words(beta, vocab, n_pos=8, n_neg=0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:D: served service sanders returning soldiers veterans members insurance ; sparsity=0.0000\n",
      "0:R: freedom always choice individuals greater control social rates ; sparsity=0.0000\n",
      "1:D: dick durbin dear request sincerely counties assistance letter ; sparsity=0.0000\n",
      "1:R: announce fire grants awarded demint equipment announces personnel ; sparsity=0.0000\n",
      "2:D: klobuchar consumers consumer drug prices industry commerce companies ; sparsity=0.0000\n",
      "2:R: mccain john choice power browse legislation regarding commitment ; sparsity=0.0000\n",
      "3:D: bill reform products klobuchar farm consumer safety commission ; sparsity=0.0000\n",
      "3:R: announces wes kevin bishop hickman carolina demint south ; sparsity=0.0000\n",
      "4:D: assistance recovery relief income counties quickly local residents ; sparsity=0.0000\n",
      "4:R: earmarks room coburn spending per bills congress transparency ; sparsity=0.0000\n",
      "5:D: fuels fuel oil renewable energy economy independence vehicles ; sparsity=0.0000\n",
      "5:R: immigration border illegal reform security temporary secure comprehensive ; sparsity=0.0000\n",
      "6:D: illinois funding project secured river serve successful construction ; sparsity=0.0000\n",
      "6:R: armed million authorization air changes almost goes purchase ; sparsity=0.0000\n",
      "7:D: electronic initiated alerts newsletters julian petitions obama pursuant ; sparsity=0.0000\n",
      "7:R: kevin browse experience john lindsey man mccain court ; sparsity=0.0000\n",
      "8:D: warming sanders troops reducing global challenge climate political ; sparsity=0.0000\n",
      "8:R: court supreme judge votes trying legal want fair ; sparsity=0.0000\n",
      "9:D: accountability dear obama security reports gibbs brundage conduct ; sparsity=0.0000\n",
      "9:R: middle iraq troops mission iraqi sacrifice send getting ; sparsity=0.0000\n"
     ]
    }
   ],
   "source": [
    "interactions = np.load(os.path.join('output', 'beta_ci.npz'))\n",
    "weights = interactions['beta']\n",
    "names = topic_covars['names']\n",
    "names = [str(k) + ':' + c for k in range(10) for c in names]\n",
    "print_top_words(weights, vocab, topic_names=names, n_pos=8, n_neg=0);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The basic topics here are now perhaps less good, but the interaction do seem to capture something about how the different parties talk about certain issues. For example, for topic 0 (veterans), The democratic version emphasizes serice, and membership, whereas the republican versionis more about freedom and choice. More data (from all the senators) would give us a much better approxaimation of this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to covariates, we can also introduce labels, which are predicted from the topics that are learned. Although they only introduce a subtle influence on the topic, we are effectively learning a classifier and a topic model simultaneously.\n",
    "\n",
    "Here, let's try predicting the party of a press release from the topics. We'll also try using more topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python run_scholar.py tutorial/congress/ -k 15 --epochs 150 --dev-folds 10 --seed 99 --topic-covars senator,month --label party\n",
      "Loading data\n",
      "Loaded 2483 documents with 1000 features\n",
      "Found 2483 non-empty documents\n",
      "Loading labels from tutorial/congress/train.party.csv\n",
      "Found 2 labels\n",
      "Loading covariates from tutorial/congress/train.senator.csv\n",
      "Loading covariates from tutorial/congress/train.month.csv\n",
      "Train label proportions: [0.54007249 0.45992751]\n",
      "Computing background frequencies\n",
      "Min/max word counts in training data: 89 5075\n",
      "Network architecture:\n",
      "embedding_dim: 300\n",
      "n_topics: 15\n",
      "vocab_size: 1000\n",
      "label_type: None\n",
      "n_labels: 2\n",
      "n_prior_covars: 0\n",
      "n_topic_covars: 18\n",
      "l1_beta_reg: 0.0\n",
      "l1_beta_c_reg: 0.0\n",
      "l1_beta_ci_reg: 0.0\n",
      "l2_prior_reg: 0.0\n",
      "classifier_layers: 1\n",
      "use_interactions: False\n",
      "Optimizing full model\n",
      "Epoch: 10 ; cost = 1124.008647057 ; training accuracy (noisy) = 0.551677852\n",
      "Epoch: 10; Dev perplexity = 1061.4584; Dev accuracy = 0.6976\n",
      "Epoch: 20 ; cost = 1080.446302171 ; training accuracy (noisy) = 0.600894855\n",
      "Epoch: 20; Dev perplexity = 918.8200; Dev accuracy = 0.6169\n",
      "Epoch: 30 ; cost = 1075.489368140 ; training accuracy (noisy) = 0.613422819\n",
      "Epoch: 30; Dev perplexity = 786.9869; Dev accuracy = 0.6129\n",
      "Epoch: 40 ; cost = 1042.560456210 ; training accuracy (noisy) = 0.633557047\n",
      "Epoch: 40; Dev perplexity = 737.7579; Dev accuracy = 0.7258\n",
      "Epoch: 50 ; cost = 1062.221849002 ; training accuracy (noisy) = 0.660402685\n",
      "Epoch: 50; Dev perplexity = 686.2696; Dev accuracy = 0.7177\n",
      "Epoch: 60 ; cost = 1047.832845052 ; training accuracy (noisy) = 0.668456376\n",
      "Epoch: 60; Dev perplexity = 654.0432; Dev accuracy = 0.7056\n",
      "Epoch: 70 ; cost = 1029.714563016 ; training accuracy (noisy) = 0.658165548\n",
      "Epoch: 70; Dev perplexity = 610.8131; Dev accuracy = 0.7218\n",
      "Epoch: 80 ; cost = 1048.704399775 ; training accuracy (noisy) = 0.662639821\n",
      "Epoch: 80; Dev perplexity = 587.5086; Dev accuracy = 0.7460\n",
      "Epoch: 90 ; cost = 1030.655558541 ; training accuracy (noisy) = 0.676957494\n",
      "Epoch: 90; Dev perplexity = 567.5784; Dev accuracy = 0.7419\n",
      "Epoch: 100 ; cost = 1048.678816896 ; training accuracy (noisy) = 0.688590604\n",
      "Epoch: 100; Dev perplexity = 544.3154; Dev accuracy = 0.7742\n",
      "Epoch: 110 ; cost = 1056.672751066 ; training accuracy (noisy) = 0.676062640\n",
      "Epoch: 110; Dev perplexity = 525.5067; Dev accuracy = 0.7823\n",
      "Epoch: 120 ; cost = 1071.785793091 ; training accuracy (noisy) = 0.702908277\n",
      "Epoch: 120; Dev perplexity = 496.5634; Dev accuracy = 0.8105\n",
      "Epoch: 130 ; cost = 1094.895112381 ; training accuracy (noisy) = 0.676957494\n",
      "Epoch: 130; Dev perplexity = 474.7009; Dev accuracy = 0.7903\n",
      "Epoch: 140 ; cost = 1071.252059083 ; training accuracy (noisy) = 0.706487696\n",
      "Epoch: 140; Dev perplexity = 458.3242; Dev accuracy = 0.7944\n",
      "Background frequencies of top words:\n",
      "senator obama bill said senate today washington graham press president\n",
      "[0.01305886 0.01280154 0.00948215 0.00868446 0.00810808 0.00686008\n",
      " 0.00643037 0.00634545 0.00602123 0.00594403]\n",
      "Topics:\n",
      "0: court supreme judge nomination legal justice position chief  / funds provides provide programs awarded billion grant providing ; sparsity=0.0000\n",
      "1: announces medical awarded announced care quality grant health  / floor president amendment senate congress just time want ; sparsity=0.0000\n",
      "2: veterans defense authorization affairs military armed members benefits  / united power protecting industry commerce region issue grant ; sparsity=0.0000\n",
      "3: insurance americans tell care class children let parents  / contact grant awarded press department browse carolina clean ; sparsity=0.0000\n",
      "4: iraq troops political war course success iraqi forces  / federal department program health programs labor education low ; sparsity=0.0000\n",
      "5: soldiers returning afghanistan sacrifice military men guard armed  / federal energy industry labor consumer green vulnerable businesses ; sparsity=0.0000\n",
      "6: tax financial taxpayers income taxpayer housing costs paying  / war honor armed nation key east regional afghanistan ; sparsity=0.0000\n",
      "7: releases browse bishop announces relases record lindsey announced  / period electronic bill amendment billion percent risk year ; sparsity=0.0000\n",
      "8: durbin dick assistance residents letter request dear sincerely  / legislation americans increasing introduced american instead middle labolt ; sparsity=0.0010\n",
      "9: projects project funding infrastructure appropriations million river transportation  / issue whether united election alerts period day general ; sparsity=0.0000\n",
      "10: commission criminal homeland conduct legal security election travel  / percent costs education rural health families energy fiscal ; sparsity=0.0000\n",
      "11: immigration reform illegal oil border gas trade prices  / awarded grant information announced receive related programs department ; sparsity=0.0000\n",
      "12: safety consumer grants fire awarded risk products departments  / period president military statement armed billions energy polls ; sparsity=0.0000\n",
      "13: energy warming renewable global sources fuels gas climate  / election armed department served abuse military office personal ; sparsity=0.0000\n",
      "14: statement initiated newsletters polls pursuant electronic alerts opinion  / number additional increase total based according average provide ; sparsity=0.0000\n",
      "sparsity in topics = 0.0001\n",
      "Covariate deviations:\n",
      "Coburn: citizen room tom per coburn spending dollars congress  / klobuchar obama releases hickman relases date sanders amy ; sparsity=0.0000\n",
      "Graham: relases press lindsey graham awarded bishop carolina wes  / amy tommy obama thursday klobuchar sanders immediate labolt ; sparsity=0.0000\n",
      "Klobuchar: klobuchar minnesota commerce amy serves consumer farm prices  / date graham tommy relases releases press wes initiated ; sparsity=0.0000\n",
      "McCain: mccain browse john record freedom rather let simply  / obama klobuchar graham bishop gibbs wes sanders tommy ; sparsity=0.0000\n",
      "Obama: obama brundage tommy barack gibbs vietor julian ortiz  / press graham carolina releases browse sanders relases bishop ; sparsity=0.0000\n",
      "Sanders: bernie sanders vermont sen http read news paying  / klobuchar amy relases releases tommy graham date wes ; sparsity=0.0000\n",
      "Apr: april location temporary prices building price attention hundreds  / june brundage september july august vietor tommy gibbs ; sparsity=0.0000\n",
      "Aug: august transportation announce grant area receive letter importance  / union polls initiated finally brundage newsletters petitions successful ; sparsity=0.0000\n",
      "Dec: december electronic pursuant provision alerts expected homes complete  / labolt june clearly company ben march advance august ; sparsity=0.0000\n",
      "Feb: february cut bipartisan budget proposed eliminate low interest  / june brundage september july established april labolt done ; sparsity=0.0000\n",
      "Jan: january economic class decisions fair things middle warming  / october labolt brundage september estimated july company march ; sparsity=0.0000\n",
      "Jul: july moving labolt sure goes ways measures per  / october brundage february november calls union september amy ; sparsity=0.0000\n",
      "Jun: june initiative system businesses labolt along programs want  / october amy brundage august september march december april ; sparsity=0.0000\n",
      "Mar: march billions budget paid labolt alone priorities consumer  / brundage june october august july control amy look ; sparsity=0.0000\n",
      "May: takes committed workers man defense domestic permanent systems  / july brundage october august follow amy terrorists june ; sparsity=0.0000\n",
      "Nov: november amy brundage win labor encourage period veto  / june ortiz noted labolt july january measure ben ; sparsity=0.0000\n",
      "Oct: october brundage amy private nomination reported human north  / labolt ortiz often june polls pursuant initiated march ; sparsity=0.0000\n",
      "Sep: september presidents chief ahead getting brundage amy addition  / initiated ortiz electronic january petitions labolt polls encourage ; sparsity=0.0000\n",
      "sparsity in covariates = 0.0000\n",
      "Dev perplexity = 447.6248\n",
      "Predicting labels\n",
      "train accuracy on labels = 0.7857\n",
      "dev accuracy on labels = 0.7903\n",
      "Label probabilities based on topics\n",
      "Labels: D R\n",
      "0: 0.1696 0.8304 \n",
      "1: 0.1392 0.8608 \n",
      "2: 0.6234 0.3766 \n",
      "3: 0.8487 0.1513 \n",
      "4: 0.4693 0.5307 \n",
      "5: 0.8374 0.1626 \n",
      "6: 0.6764 0.3236 \n",
      "7: 0.0032 0.9968 \n",
      "8: 0.9229 0.0771 \n",
      "9: 0.4275 0.5725 \n",
      "10: 0.6437 0.3563 \n",
      "11: 0.2332 0.7668 \n",
      "12: 0.3234 0.6766 \n",
      "13: 0.9301 0.0699 \n",
      "14: 0.9944 0.0056 \n",
      "Saving document representations\n"
     ]
    }
   ],
   "source": [
    "script = 'run_scholar.py'\n",
    "args = 'tutorial/congress/ -k 15 --epochs 150 --dev-folds 10 --seed 99 --topic-covars senator,month --label party'\n",
    "print(\"python\", script, args)\n",
    "run_scholar.main(args.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's look at the topics as usual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: court supreme judge nomination legal justice position chief ; sparsity=0.0000\n",
      "1: announces medical awarded announced care quality grant health ; sparsity=0.0000\n",
      "2: veterans defense authorization affairs military armed members benefits ; sparsity=0.0000\n",
      "3: insurance americans tell care class children let parents ; sparsity=0.0000\n",
      "4: iraq troops political war course success iraqi forces ; sparsity=0.0000\n",
      "5: soldiers returning afghanistan sacrifice military men guard armed ; sparsity=0.0000\n",
      "6: tax financial taxpayers income taxpayer housing costs paying ; sparsity=0.0000\n",
      "7: releases browse bishop announces relases record lindsey announced ; sparsity=0.0000\n",
      "8: durbin dick assistance residents letter request dear sincerely ; sparsity=0.0010\n",
      "9: projects project funding infrastructure appropriations million river transportation ; sparsity=0.0000\n",
      "10: commission criminal homeland conduct legal security election travel ; sparsity=0.0000\n",
      "11: immigration reform illegal oil border gas trade prices ; sparsity=0.0000\n",
      "12: safety consumer grants fire awarded risk products departments ; sparsity=0.0000\n",
      "13: energy warming renewable global sources fuels gas climate ; sparsity=0.0000\n",
      "14: statement initiated newsletters polls pursuant electronic alerts opinion ; sparsity=0.0000\n"
     ]
    }
   ],
   "source": [
    "beta = np.load(os.path.join('output', 'beta.npz'))['beta']\n",
    "print_top_words(beta, vocab, n_pos=8, n_neg=0);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look at which topics predict Democrat vs Republican."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels: D R\n",
      "0: 0.1696 0.8304 \n",
      "1: 0.1392 0.8608 \n",
      "2: 0.6234 0.3766 \n",
      "3: 0.8487 0.1513 \n",
      "4: 0.4693 0.5307 \n",
      "5: 0.8374 0.1626 \n",
      "6: 0.6764 0.3236 \n",
      "7: 0.0032 0.9968 \n",
      "8: 0.9229 0.0771 \n",
      "9: 0.4275 0.5725 \n",
      "10: 0.6437 0.3563 \n",
      "11: 0.2332 0.7668 \n",
      "12: 0.3234 0.6766 \n",
      "13: 0.9301 0.0699 \n",
      "14: 0.9944 0.0056 \n"
     ]
    }
   ],
   "source": [
    "npz = np.load('output/topics_to_labels.npz')\n",
    "probs = npz['probs']\n",
    "label_names = npz['label']\n",
    "n_topics, n_labels = probs.shape\n",
    "print(\"Labels:\", ' '.join([name for name in label_names]))\n",
    "for k in range(n_topics):\n",
    "    output = str(k) + ': '\n",
    "    for i in range(n_labels):\n",
    "        output += '%.4f ' % probs[k, i]\n",
    "    print(output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These numbers show the probability (according to the model) that a document entirely about a single topic is from a Democrat vs a Republican. Of course, in practice, most documents will be represented as a mixture of topics, and both parties talk about all topics to some degree.\n",
    "\n",
    "Some of these associations seem to be possibly over-fitting to certain stylistic differences (e.g. topics 14 and 7), but others do seem to be capturing party priorities, such as the supreme court, immigration, and the environment. Again more data from more Senators would help here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ultimately, exploration of different models is requried to figure out what is best for your application. Also, remember than trying a different random seed will give you different results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
