{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scholar is a framework for document modeling, much like LDA, but with the ability to flexibly incorporate metadata, with some similarity to the structural topic model. It can scale to large numbers of covariates, runs in python, and offers GPU support for fast exploration of a corpus of documents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we'll use a toy corpus of political press releases in order to demonstrate the functionality and interface of Scholar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code\n",
    "\n",
    "If you're looking at this tutorial, you have presumably already downloaded/cloned the Scholar repo. If not, you can clone it using: \n",
    "\n",
    "`git clone git@github.com:dallascard/scholar.git`\n",
    "\n",
    "(if you don't have git set up, you can just download the repo from https://github.com/dallascard/scholar)\n",
    "\n",
    "Scholar has not yet been packaged us as a full python packge. As such, we will just run commands from the scholar directory, so switch into it:\n",
    "\n",
    "`cd /path/to/scholar`\n",
    "\n",
    "(the directory that contains this notebook)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment\n",
    "\n",
    "Create new python environment for running scholar. We recommend using Anaconda, but it is also possible to do this using virtualenv and pip. Assuming you are using conda, run the following three commands, one at a time, and follow the prompts:\n",
    "\n",
    "`conda create -n scholar python=3`\n",
    "\n",
    "`source activate scholar`\n",
    "\n",
    "`conda install ipython notebook numpy scipy pandas matplotlib gensim pytorch torchvision -c pytorch`\n",
    "\n",
    "You should also now quit this notebook and reload it from with the scholar environment (i.e. after running `source activate scholar` in the shell)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data\n",
    "\n",
    "For this tutorial, we'll be using a subset of the Congressional press release corpus created by Justin Grimmer.\n",
    "\n",
    "A compressed file with press releases from six senators can be found in this repo. To expand it, run\n",
    "\n",
    "`tar -xzf tutorial.tar.gz`\n",
    "\n",
    "which will create a Â directory called  `tutorial/CongressPressExpand/`\n",
    "\n",
    "For those who are interested, the full dataset (Press.tar; 282Mb) can be downloaded from https://dataverse.harvard.edu/dataset.xhtml?persistentId=hdl:1902.1/14596"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Import\n",
    "\n",
    "To use scholar, it is necessary to get the data into the proper format. To do this, the easiest thing to do is to write a script to convert the documents into a single file, where each line corresponds to one document, represented as a JSON object. Each JSON object should have at least one field called \"text\", but it can also contain other metadata fields.\n",
    "\n",
    "We have included a script to convert a subset of the Senatorial press releases into this format, which can be used as a starting point for your own project.\n",
    "\n",
    "If running this from the command line, it would be run as\n",
    "\n",
    "`python import_congress_press.py tutorial/CongressPressExpand tutorial/congress/`\n",
    "\n",
    "Since we are running this in a notebook, we will run it by importing the package, and calling the `main()` function with the corresponding arguments in a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python import_congress_press tutorial/CongressPressExpand tutorial/congress\n",
      "274 files from Sanders\n",
      "709 files from Obama\n",
      "358 files from Klobuchar\n",
      "293 files from McCain\n",
      "614 files from Graham\n",
      "235 files from Coburn\n",
      "Saving files to tutorial/congress\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "import import_congress_press\n",
    "script = 'import_congress_press'\n",
    "args = 'tutorial/CongressPressExpand tutorial/congress'\n",
    "print(\"python\", script, args)\n",
    "import_congress_press.main(args.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This creates two files in the output directory (`/tutorial/congress/`):\n",
    "- `train.jsonlist` contains one press release per line, in JSON format, including fields for the text of the press release, as well as senator name, party, date, year, and month\n",
    "- `train.score.csv` contains DW-nominate scores for 6 senators from the 110th congress, with one score for each document in `train.jsonlist` (in the same order)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To inspect a document, we can use the `json` library to load it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id : 10Apr2007Sanders238.txt\n",
      "text : SEIZE THE OPPORTUNITY FOR MAJOR BREAKTHROUGHS IN HEALTH CARE   The Senate this week is considering a bill, cosponsored by Sen. Bernie Sanders, that would expand and encourage federal funding of human embryonic stem cell research. President Bush in 2001 cut off federal funding for research involving new embryonic stem cells, which has dramatically stalled this critical area of medical research.      \"My hope is that, as a result of increased pressure from scientists, physicians and the American people, the president will change his position or, if he does not, that the Congress will have enough votes to override his veto and establish unrestricted federal funding for stem cell research,\" Sanders said. \"The potential is now available for major breakthroughs in Parkinson's disease, Alzheimer's, diabetes, spinal cord injury, stroke, heart disease and many other illnesses. We must seize the opportunity.\"     View a copy of the Bill - S. 5 at http://sanders.senate.gov/files/S_5.pdf    Read a summary of the bill - S. 5 at http://www.sanders.senate.gov/news/record.cfm?id=272151    Read a Congressional Research Service background report on stem cell research at http://sanders.senate.gov/files/Stem%20Cells.pdf.    \n",
      "senator : Sanders\n",
      "date : 10Apr2007\n",
      "year : 2007\n",
      "month : Apr\n",
      "party : D\n",
      "score : -0.717\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "with open(os.path.join('tutorial', 'congress', 'train.jsonlist')) as f:\n",
    "    lines = f.readlines()\n",
    "first_doc = json.loads(lines[0])\n",
    "for key, value in first_doc.items():\n",
    "    print(key, ':', value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we had documents that we wanted to use as a test set, we could create a `test.jsonlist` object in the same manner."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to use a preprocessing script we have provided to convert the documents from JSON format into a numerical representation. It works by creating a vocabulary, filtering out numbers, punctuation, and some other tokens, and saving the document-term count matrix. \n",
    "\n",
    "The preprocessing script can also simultaneously pull out various metadata attributes (like author or year) from the JSON objects, and convert them into one-hot representations, which will be saved as .csv files.\n",
    "\n",
    "For other types of metadata, such as continously-valued data, you will need to create the corresponding .csv files manually, as we did above for `train.score.csv`. All that matters is that the order of the rows is the same as the the order of documents in `train.jsonlist`. Also, scholar will expect the file name to be `train.field_name.csv` (or \"test\" rather than \"train\" for test data)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see the full set of options for any command, try running it with the `-h` option. Again, in the shell, this would be run as:\n",
    "\n",
    "`python preprocess_data.py -h`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python preprocess_data.py -h\n",
      "Usage: ipykernel_launcher.py train.jsonlist output_dir\n",
      "\n",
      "Options:\n",
      "  -h, --help            show this help message and exit\n",
      "  --label=LABEL         field(s) to use as label (comma-separated):\n",
      "                        default=none\n",
      "  --test=TEST           Test data (test.jsonlist): default=none\n",
      "  --train-prefix=TRAIN_PREFIX\n",
      "                        Output prefix for training data: default=train\n",
      "  --test-prefix=TEST_PREFIX\n",
      "                        Output prefix for test data: default=test\n",
      "  --stopwords=STOPWORDS\n",
      "                        List of stopwords to exclude [None|mallet|snowball]:\n",
      "                        default=snowball\n",
      "  --min-doc-count=MIN_DOC_COUNT\n",
      "                        Exclude words that occur in less than this number of\n",
      "                        documents\n",
      "  --max-doc-freq=MAX_DOC_FREQ\n",
      "                        Exclude words that occur in more than this proportion\n",
      "                        of documents\n",
      "  --keep-num            Keep tokens made of only numbers: default=False\n",
      "  --keep-alphanum       Keep tokens made of a mixture of letters and numbers:\n",
      "                        default=False\n",
      "  --strip-html          Strip HTML tags: default=False\n",
      "  --no-lower            Do not lowercase text: default=False\n",
      "  --min-length=MIN_LENGTH\n",
      "                        Minimum token length: default=3\n",
      "  --vocab-size=VOCAB_SIZE\n",
      "                        Size of the vocabulary (by most common, following\n",
      "                        above exclusions): default=none\n",
      "  --seed=SEED           Random integer seed (only relevant for choosing test\n",
      "                        set): default=42\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dcard/anaconda/envs/pytorch4/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2969: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import preprocess_data\n",
    "args = '-h'\n",
    "print(\"python preprocess_data.py -h\")\n",
    "preprocess_data.main([args])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we'll tell it to only use words that occur in at least 90 documents, which will give us a vocabulary of about 1000 words (excluding stopwords). This will help the model run faster, but using a larger vocabulary (2000 or 5000 words, might lead to much richer topics). Alternatively, we could set the vocabulary size directly, using `--vocab-size`\n",
    "\n",
    "We'll also tell it to create the label matrices for the various metadata attributes, which we provide in a comma-separated list (without spaces). As a reminder, it will assume that each of these metadata names will be a field in each JSON document object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python preprocess_data.py tutorial/congress/train.jsonlist tutorial/congress --min-doc-count 90 --label senator,party,year,month,date\n",
      "Using snowball stopwords\n",
      "Reading data files\n",
      "Found 2483 training documents\n",
      "Found label senator with 6 classes\n",
      "Found label party with 2 classes\n",
      "Found label year with 4 classes\n",
      "Found label month with 12 classes\n",
      "Found label date with 918 classes\n",
      "Parsing 2483 documents\n",
      "Size of full vocabulary=22131\n",
      "Selecting the vocabulary\n",
      "Vocab size after filtering = 1021\n",
      "Final vocab size = 1021\n",
      "Most common words remaining: senator washington today said senate contact press also current date\n",
      "Converting to count representations\n",
      "Size of train document-term matrix: (2483, 1021)\n",
      "0 words missing from training data\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "script = 'preprocess_data.py'\n",
    "args = 'tutorial/congress/train.jsonlist tutorial/congress --min-doc-count 90 --label senator,party,year,month,date'\n",
    "print(\"python\", script, args)\n",
    "preprocess_data.main(args.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This preprocessing script creates several files, some uesd by Scholar, and some designed for other software, like Mallet. The files of interest are:\n",
    "- `train.npz`, which contains a (D x V) sparse matrix of document word counts,\n",
    "- `train.vocab.json`, which contains the vocabualry as a JSON object, and;\n",
    "- files like `train.year.csv`, which contain the year corresponding to each document, in a matrix of size (D x C), where C is the number of distinct covariate values (e.g. years)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at a couple of files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First few words in the vocbulary:\n",
      "['ability', 'able', 'abuse', 'access', 'according', 'accountability', '...']\n"
     ]
    }
   ],
   "source": [
    "# load the vocabualry\n",
    "with open(os.path.join('tutorial', 'congress', 'train.vocab.json')) as f:\n",
    "    vocab = json.load(f)\n",
    "print(\"First few words in the vocbulary:\")\n",
    "print(vocab[:6] + ['...'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start of a covariate file (train.year.csv):\n",
      "                         2005  2006  2007  2008\n",
      "10Apr2007Sanders238.txt     0     0     1     0\n",
      "10Apr2008Sanders2.txt       0     0     0     1\n",
      "10Apr2008Sanders3.txt       0     0     0     1\n",
      "10Dec2007Sanders61.txt      0     0     1     0\n",
      "10May2007Sanders212.txt     0     0     1     0\n"
     ]
    }
   ],
   "source": [
    "# load a covariate file\n",
    "import pandas as pd\n",
    "print(\"Start of a covariate file (train.year.csv):\")\n",
    "df = pd.read_csv(os.path.join('tutorial', 'congress', 'train.year.csv'), header=0, index_col=0)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that if we had a test corpus, we could simultaneously process it by adding the `--test` option to our call to `preprocess_data` (with the path to `test.jsonlist`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running Scholar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to run Scholar!\n",
    "\n",
    "To start off, let's just run a basic topic model, without any metadata. We just need to specify the input directory,  and it will look for the `train.npz` file, as well as `train.vocab.json`. \n",
    "\n",
    "Here, we'll also tell it to use 10 topics (`-k`), tell it only to run for 50 epochs (`--epochs 50`), and to use a random 1/10th of the data as a dev/validation set to monitor the fit (`--dev-folds 10`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python run_scholar.py tutorial/congress/ -k 10 --epochs 50 --dev-folds 10 --seed 99\n",
      "Loading data\n",
      "Loaded 2483 documents with 1021 features\n",
      "Found 2483 non-empty documents\n",
      "Computing background frequencies\n",
      "Min/max word counts in training data: 88 5075\n",
      "Network architecture:\n",
      "embedding_dim: 300\n",
      "n_topics: 10\n",
      "vocab_size: 1021\n",
      "label_type: None\n",
      "n_labels: 0\n",
      "n_prior_covars: 0\n",
      "n_topic_covars: 0\n",
      "l1_beta_reg: 0.0\n",
      "l1_beta_c_reg: 0.0\n",
      "l1_beta_ci_reg: 0.0\n",
      "l2_prior_reg: 0.0\n",
      "classifier_layers: 1\n",
      "use_interactions: False\n",
      "Optimizing full model\n",
      "Epoch: 10 cost= 1123.892300668\n",
      "Epoch: 10; Dev perplexity = inf\n",
      "Epoch: 20 cost= 1109.053324245\n",
      "Epoch: 20; Dev perplexity = 78207346.2447\n",
      "Epoch: 30 cost= 1124.218160130\n",
      "Epoch: 30; Dev perplexity = 1221.7934\n",
      "Epoch: 40 cost= 1108.377098408\n",
      "Epoch: 40; Dev perplexity = 784.0064\n",
      "Background frequencies of top words:\n",
      "senator obama bill said senate today washington graham press president\n",
      "[0.01296816 0.01271263 0.00941629 0.00862415 0.00805176 0.00681244\n",
      " 0.00638571 0.00630138 0.00597941 0.00590275]\n",
      "Topics:\n",
      "0: energy fuel renewable oil fuels bill obama klobuchar  / bishop browse hickman supreme press kevin releases judge ; sparsity=0.0000\n",
      "1: today statement washington congress time senator government current  / receive fire grants program carolina grant care south ; sparsity=0.0000\n",
      "2: iraq president war political time people american iraqi  / energy communities programs announced community receive grants development ; sparsity=0.0000\n",
      "3: bill congress year senate million president earmarks billion  / contact date hickman carolina kevin announces relases south ; sparsity=0.0000\n",
      "4: record browse lindsey wes press bishop date hickman  / legislation make act many american need one also ; sparsity=0.0000\n",
      "5: washington statement barack obama release following released coburn  / support national graham funding carolina south program system ; sparsity=0.0000\n",
      "6: klobuchar said children minnesota also lead legislation care  / contact date bishop wes carolina hickman security kevin ; sparsity=0.0010\n",
      "7: care health veterans year million sanders percent college  / hickman relases wes releases lindsey carolina south browse ; sparsity=0.0000\n",
      "8: obama barack durbin senator alerts federal newsletters office  / carolina research billion browse projects bishop south million ; sparsity=0.0000\n",
      "9: press south graham grants carolina awarded fire releases  / government act years legislation last make american country ; sparsity=0.0000\n",
      "sparsity in topics = 0.0001\n",
      "Dev perplexity = 724.3032\n",
      "Saving document representations\n"
     ]
    }
   ],
   "source": [
    "import run_scholar\n",
    "script = 'run_scholar.py'\n",
    "args = 'tutorial/congress/ -k 10 --epochs 50 --dev-folds 10 --seed 99'\n",
    "print(\"python\", script, args)\n",
    "run_scholar.main(args.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To display this a bit more cleanly, let's load the output and look at it.\n",
    "\n",
    "By default, the output of the model is saved to a directory called `output`, but that can be changed using the `-o` option (remember to use `-h` to see all options).\n",
    "\n",
    "First, let's inspect the background frequencies of the most common words (the log-frequencies are computed and saved)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "senator 0.012968165\n",
      "obama 0.012712633\n",
      "bill 0.009416293\n",
      "said 0.008624149\n",
      "senate 0.008051763\n",
      "today 0.006812439\n",
      "washington 0.0063857054\n",
      "graham 0.00630138\n",
      "press 0.0059794127\n",
      "president 0.005902752\n",
      "legislation 0.00572388\n",
      "barack 0.005562898\n",
      "health 0.0055398997\n",
      "million 0.00542491\n",
      "federal 0.005355918\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "\n",
    "# load the background log-frequencies\n",
    "bg = np.load('output/bg.npz')['bg']\n",
    "\n",
    "# load the vocabualry\n",
    "with open('output/vocab.json') as f:\n",
    "    vocab = json.load(f)\n",
    "\n",
    "# sort terms by log-frequency\n",
    "order = np.argsort(bg)\n",
    "\n",
    "# print the most common words \n",
    "for i in range(1, 16):\n",
    "    index = order[-i]\n",
    "    print(vocab[index], np.exp(bg[index]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This seems like about what we would expect for the most common words, including common words, like \"said\", corpus-specific words, like \"senator\", and the names of some of the Senators we have included.\n",
    "\n",
    "Typically in topic models, we might need to remove stopwords to get good topics, but in Scholar the background term means that we don't particularly need to worry about it. (Note that the prepocessing script removed some very common words like \"the\", but they could equally have been left in).\n",
    "\n",
    "Now let's look at the topics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: energy fuel renewable oil fuels bill obama klobuchar ; sparsity=0.0000\n",
      "1: today statement washington congress time senator government current ; sparsity=0.0000\n",
      "2: iraq president war political time people american iraqi ; sparsity=0.0000\n",
      "3: bill congress year senate million president earmarks billion ; sparsity=0.0000\n",
      "4: record browse lindsey wes press bishop date hickman ; sparsity=0.0000\n",
      "5: washington statement barack obama release following released coburn ; sparsity=0.0000\n",
      "6: klobuchar said children minnesota also lead legislation care ; sparsity=0.0010\n",
      "7: care health veterans year million sanders percent college ; sparsity=0.0000\n",
      "8: obama barack durbin senator alerts federal newsletters office ; sparsity=0.0000\n",
      "9: press south graham grants carolina awarded fire releases ; sparsity=0.0000\n"
     ]
    }
   ],
   "source": [
    "from run_scholar import print_top_words\n",
    "\n",
    "# load the stored (K x V) topic matrix (stored in a compressed numpy format)\n",
    "beta = np.load(os.path.join('output', 'beta.npz'))['beta']\n",
    "print_top_words(beta, vocab, n_pos=8, n_neg=0);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is some order here, such as topic 0 being about energy, but overall these topics are not great.\n",
    "\n",
    "One problem is that we are still seeing names like \"Obama\" and \"Barack\" appearing in the topics, which is not quite what we want. To deal with this, let's add topic covariates, to introduce explicit term for each Senator, to collect the words that are more or less common overall for each one.\n",
    "\n",
    "We'll also let the model run for more epochs, to help it converge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding covariates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we introduce the `--topic-covars` option, which introduces topic-like deviations for observed one-hot covariates. Thus, in addition to the 10 topics, we will here get 6 more vectors of word weights, one for each Senator.\n",
    "\n",
    "When we add the option `--topic-covars senator`, it will look for a file called `train.senator.csv`, with one row for each document, in the same order as `train.jsonlist`. (As a reminder, this file was created by `preprocess_data.py`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python run_scholar.py tutorial/congress/ -k 10 --epochs 150 --dev-folds 10 --seed 99 --topic-covars senator\n",
      "Loading data\n",
      "Loaded 2483 documents with 1021 features\n",
      "Found 2483 non-empty documents\n",
      "Loading covariates from tutorial/congress/train.senator.csv\n",
      "Computing background frequencies\n",
      "Min/max word counts in training data: 88 5075\n",
      "Network architecture:\n",
      "embedding_dim: 300\n",
      "n_topics: 10\n",
      "vocab_size: 1021\n",
      "label_type: None\n",
      "n_labels: 0\n",
      "n_prior_covars: 0\n",
      "n_topic_covars: 6\n",
      "l1_beta_reg: 0.0\n",
      "l1_beta_c_reg: 0.0\n",
      "l1_beta_ci_reg: 0.0\n",
      "l2_prior_reg: 0.0\n",
      "classifier_layers: 1\n",
      "use_interactions: False\n",
      "Optimizing full model\n",
      "Epoch: 10 cost= 1149.467740667\n",
      "Epoch: 10; Dev perplexity = 878.8163\n",
      "Epoch: 20 cost= 1107.047984829\n",
      "Epoch: 20; Dev perplexity = 827.7426\n",
      "Epoch: 30 cost= 1102.188625122\n",
      "Epoch: 30; Dev perplexity = 741.1453\n",
      "Epoch: 40 cost= 1066.253058585\n",
      "Epoch: 40; Dev perplexity = 672.0257\n",
      "Epoch: 50 cost= 1087.087200259\n",
      "Epoch: 50; Dev perplexity = 628.2367\n",
      "Epoch: 60 cost= 1070.249596922\n",
      "Epoch: 60; Dev perplexity = 606.9425\n",
      "Epoch: 70 cost= 1049.033093890\n",
      "Epoch: 70; Dev perplexity = 586.5134\n",
      "Epoch: 80 cost= 1067.080487757\n",
      "Epoch: 80; Dev perplexity = 558.6682\n",
      "Epoch: 90 cost= 1047.719491707\n",
      "Epoch: 90; Dev perplexity = 539.2626\n",
      "Epoch: 100 cost= 1064.388435927\n",
      "Epoch: 100; Dev perplexity = 523.4846\n",
      "Epoch: 110 cost= 1070.233266263\n",
      "Epoch: 110; Dev perplexity = 512.4081\n",
      "Epoch: 120 cost= 1086.223909178\n",
      "Epoch: 120; Dev perplexity = 496.3190\n",
      "Epoch: 130 cost= 1109.989546193\n",
      "Epoch: 130; Dev perplexity = 478.7304\n",
      "Epoch: 140 cost= 1088.349188820\n",
      "Epoch: 140; Dev perplexity = 465.5977\n",
      "Background frequencies of top words:\n",
      "senator obama bill said senate today washington graham press president\n",
      "[0.01296816 0.01271263 0.00941629 0.00862415 0.00805176 0.00681244\n",
      " 0.00638571 0.00630138 0.00597941 0.00590275]\n",
      "Topics:\n",
      "0: fuels energy fuel renewable gas oil reduce climate  / emergency afghanistan demint military department county appropriations personnel ; sparsity=0.0000\n",
      "1: troops war iraq terror iraqi political mission course  / million demint announced district programs grant communities awarded ; sparsity=0.0000\n",
      "2: river projects infrastructure project natural water land communities  / american statement brave age instead people pay right ; sparsity=0.0000\n",
      "3: care members armed military benefits soldiers veterans men  / change natural wes hickman interest energy farm people ; sparsity=0.0000\n",
      "4: statement following tommy passing court nomination judge released  / provide percent increase providing cost programs million total ; sparsity=0.0000\n",
      "5: workers legal don immigration laws country just people  / programs awarded demint wes grant million billion hickman ; sparsity=0.0000\n",
      "6: spending fiscal billion budget priorities income bills debt  / dear communications honorable text climate apply please releases ; sparsity=0.0000\n",
      "7: newsletters alerts petitions ortiz opinion initiated primary polls  / percent billion million average pay credit bill reduce ; sparsity=0.0000\n",
      "8: consumer lead transparency commission products children accountability commerce  / throughout world hickman rural community wes east brave ; sparsity=0.0000\n",
      "9: awarded announces departments grants grant education receive announce  / time last states now bush president instead like ; sparsity=0.0000\n",
      "sparsity in topics = 0.0000\n",
      "Covariate deviations:\n",
      "Coburn: citizen tom room coburn per added earmarks dollars  / releases wes klobuchar date kevin obama south announces ; sparsity=0.0000\n",
      "Graham: wes hickman bishop releases browse press demint graham  / barack bernie monday initiated wednesday thursday immediate minnesota ; sparsity=0.0000\n",
      "Klobuchar: minnesota klobuchar cities serves secured commerce amy consumer  / browse wes vermont press hickman obama vietor kevin ; sparsity=0.0000\n",
      "McCain: john browse mccain freedom greater releases current rather  / hickman amy bishop obama klobuchar vermont bernie tommy ; sparsity=0.0000\n",
      "Obama: gibbs vietor obama ortiz polls barack chicago initiated  / browse releases wes press hickman lindsey klobuchar vermont ; sparsity=0.0000\n",
      "Sanders: vermont bernie sanders warming paying sen bush middle  / hickman wes demint browse graham lindsey obama washington ; sparsity=0.0000\n",
      "sparsity in covariates = 0.0000\n",
      "Dev perplexity = 456.6098\n",
      "Saving document representations\n"
     ]
    }
   ],
   "source": [
    "script = 'run_scholar.py'\n",
    "args = 'tutorial/congress/ -k 10 --epochs 150 --dev-folds 10 --seed 99 --topic-covars senator'\n",
    "print(\"python\", script, args)\n",
    "run_scholar.main(args.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, let's load the topics and have a look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: fuels energy fuel renewable gas oil reduce climate ; sparsity=0.0000\n",
      "1: troops war iraq terror iraqi political mission course ; sparsity=0.0000\n",
      "2: river projects infrastructure project natural water land communities ; sparsity=0.0000\n",
      "3: care members armed military benefits soldiers veterans men ; sparsity=0.0000\n",
      "4: statement following tommy passing court nomination judge released ; sparsity=0.0000\n",
      "5: workers legal don immigration laws country just people ; sparsity=0.0000\n",
      "6: spending fiscal billion budget priorities income bills debt ; sparsity=0.0000\n",
      "7: newsletters alerts petitions ortiz opinion initiated primary polls ; sparsity=0.0000\n",
      "8: consumer lead transparency commission products children accountability commerce ; sparsity=0.0000\n",
      "9: awarded announces departments grants grant education receive announce ; sparsity=0.0000\n"
     ]
    }
   ],
   "source": [
    "beta = np.load('output/beta.npz')['beta']\n",
    "print_top_words(beta, vocab, n_pos=8, n_neg=0);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These look much better! There are fairly clear topics for the energy, military, spending, etc.\n",
    "\n",
    "In addition, we can load the vectors that have been learned for each Senator, which will be saved in a file called `beta_c.npz`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coburn: citizen tom room coburn per added earmarks dollars ; sparsity=0.0000\n",
      "Graham: wes hickman bishop releases browse press demint graham ; sparsity=0.0000\n",
      "Klobuchar: minnesota klobuchar cities serves secured commerce amy consumer ; sparsity=0.0000\n",
      "McCain: john browse mccain freedom greater releases current rather ; sparsity=0.0000\n",
      "Obama: gibbs vietor obama ortiz polls barack chicago initiated ; sparsity=0.0000\n",
      "Sanders: vermont bernie sanders warming paying sen bush middle ; sparsity=0.0000\n"
     ]
    }
   ],
   "source": [
    "topic_covars = np.load(os.path.join('output', 'beta_c.npz'))\n",
    "weights = topic_covars['beta']\n",
    "names = topic_covars['names']\n",
    "print_top_words(weights, vocab, topic_names=names, n_pos=8, n_neg=0);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are clearly about right, in that the Senator's names and/or states are appearing in the right vectors. It is hard to make sense of some of these, but they appear to doing the right thing in terms of pulling the Senator-specific terms out of the topics.\n",
    "\n",
    "Note that if we had used the full dataset, we could easily extend the covariates to include a variable for each Senator without difficulty, which would be quite slow to run in the structural topic model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing results\n",
    "\n",
    "Let's load the resulting document-topic proportions for the training data, and look a random example. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10Apr2008Sanders2.txt\n",
      "SENATE ADOPTS SANDERS VETERANS PROVISION IN HOUSING BILL   The Senate today put finishing touches on housing stimulus legislation, adding a $57 million proposal authored by Senator Bernie Sanders (I-Vt.) that would increase federal grants to help disabled veterans adapt their homes.     \"With so many soldiers coming back from Iraq with disabilities, it is absolutely imperative that we make sure they have as normal a life as possible and that certainly includes adapting their homes to meet their needs,\" Sanders said.    The final bill, which the Senate approved 84 to 12, also included energy tax credits cosponsored by Sanders that would promote renewable energy and energy efficiency. It would extend expiring federal tax benefits for investment in solar, wind and other sustainable energy sources.    Sanders also was the lead cosponsor of a successful amendment by Senator Patrick Leahy (D-Vt.) that would guarantee Vermont a $20 million share of $4 billion in community development block grants to prevent home foreclosures and to refurbish abandoned homes.    Under the veterans amendment, veterans with certain severe service-connected disabilities would be eligible for grants of up to $60,000, a $10,000 boost from the current law, to build wheelchair ramps and to make other changes so they could live at home. Veterans who were blinded or lost arms in war zones or while on active duty may receive up to $12,000, a $2,000 increase, for remodeling their homes.    The amendment also would provide for automatic annual adjustments pegged to a home construction cost index to ensure that the benefits keep pace with rising prices. Wounded veterans returning from Iraq and Afghanistan have found that the program now on the books does not cover all of the costs of adapting their homes.    Sanders' amendment was supported by the American Legion, Veterans of Foreign Wars, Disabled American Veterans, Vietnam Veterans of America, AMVETS, Paralyzed Veterans of America and others.    Before passing the bill, the Senate also added the energy provisions. \"There are huge opportunities that we will lose if we do not extend these sustainable energy tax credits,\" Sanders said. \"Not only will these tax credits enable us to continue our effort to break our dependency on the fossil fuels that cause global warming and pollute our environment, but they will provide a significant number of good-paying green jobs in the areas of wind, solar and geothermal - something that I am working very hard on and believe has tremendous potential for our economy.\"    The Leahy-Sanders Amendment would allot $20 million to help Vermont deal with the foreclosure crisis that is sweeping the country. \"With this funding, it is my hope that Vermont's cities and towns will be able to provide immediate assistance to the struggling middle class trying to hold onto their homes and improve communities hit hard by foreclosures,\" Sanders said. \"Clearly, we must do everything we can to prevent the American dream of homeownership from turning into the American nightmare of foreclosure that too many American families are experiencing.\"    \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# load the matrix with topic proportions for each document (note that this excludes those in the dev set).\n",
    "npz = np.load(os.path.join('output', 'theta.train.npz')) \n",
    "ids = npz['ids']\n",
    "theta = npz['theta']\n",
    "n_docs, n_topics = theta.shape\n",
    "\n",
    "index = 1\n",
    "# plot the proportion of each topic in the first document\n",
    "fig, ax = plt.subplots()\n",
    "ax.bar(range(n_topics), theta[index, :])\n",
    "\n",
    "# find the original line corresponding to this document, and display the text\n",
    "print(ids[index])\n",
    "for line in lines:\n",
    "    doc = json.loads(line)\n",
    "    if doc['id'] == ids[index]:\n",
    "        print(doc['text'])\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This seems about right! The press release is mostly about veterans (topic 3), but also about spending (topic 6), with some amount of energy (topic 0) and infrastructure (topic 2)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's plot the relative prevalance of each topics for each Senator.\n",
    "\n",
    "Because scholar split the training data into a training set and a dev set, we need to match up the output to the original senator variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# load the senator variable for all the documents\n",
    "senators_df = pd.read_csv(os.path.join('tutorial', 'congress', 'train.senator.csv'), header=0, index_col=0)\n",
    "senators = senators_df.columns\n",
    "\n",
    "# pull out a subset corresponding to the ids from above\n",
    "train_subset = senators_df.loc[ids]\n",
    "n_docs, n_senators = train_subset.shape\n",
    "\n",
    "# plot the average senator-topic proportions\n",
    "fig, ax = plt.subplots()\n",
    "lefts = np.zeros(n_senators)\n",
    "for k in range(n_topics):\n",
    "    vals = []\n",
    "    for senator in senators:\n",
    "        vals.append(np.mean(theta[train_subset[senator] == 1, k]))\n",
    "\n",
    "    ax.barh(range(n_senators), vals, left=lefts)\n",
    "    lefts += np.array(vals)\n",
    "    \n",
    "ax.set_yticks(range(n_senators))\n",
    "ax.set_yticklabels(senators)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This seems to have at least some face validity, with, for example, Amy Klobuchar writing more about energy/environment/infrastructure issues (topics 0 and 2), but more expertise would be useful in exploring this further. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing with pretrained word vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Emperically, we found that initializing the model with pretrained word vectors led to greater coherence in the topics. If you are interested in trying this, it is necessary to download the pretrained word2vec vectors from https://drive.google.com/file/d/0B7XkCwpI5KDYNlNUTTlSS21pQmM/edit?usp=sharing\n",
    "\n",
    "Once this is done, and these have been saved somewhere, we can add the `--w2v` option to the model, with a path to the vector file. Here, we'll assume it's in the local directory.\n",
    "\n",
    "Note that it takes some time to load the word vectors, so we'll just try this once for illustration purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python run_scholar.py tutorial/congress/ -k 10 --epochs 150 --dev-folds 10 --seed 99 --topic-covars senator --w2v ./vectors/GoogleNews-vectors-negative300.bin\n",
      "Loading data\n",
      "Loaded 2483 documents with 1021 features\n",
      "Found 2483 non-empty documents\n",
      "Loading covariates from tutorial/congress/train.senator.csv\n",
      "Computing background frequencies\n",
      "Min/max word counts in training data: 88 5075\n",
      "Network architecture:\n",
      "embedding_dim: 300\n",
      "n_topics: 10\n",
      "vocab_size: 1021\n",
      "label_type: None\n",
      "n_labels: 0\n",
      "n_prior_covars: 0\n",
      "n_topic_covars: 6\n",
      "l1_beta_reg: 0.0\n",
      "l1_beta_c_reg: 0.0\n",
      "l1_beta_ci_reg: 0.0\n",
      "l2_prior_reg: 0.0\n",
      "classifier_layers: 1\n",
      "use_interactions: False\n",
      "Loading word vectors\n",
      "Found embeddings for 1012 words\n",
      "Optimizing full model\n",
      "Epoch: 10 cost= 1128.703389349\n",
      "Epoch: 10; Dev perplexity = 840.9305\n",
      "Epoch: 20 cost= 1130.367685612\n",
      "Epoch: 20; Dev perplexity = 687.7510\n",
      "Epoch: 30 cost= 1083.127119162\n",
      "Epoch: 30; Dev perplexity = 632.9374\n",
      "Epoch: 40 cost= 1075.399669673\n",
      "Epoch: 40; Dev perplexity = 611.5000\n",
      "Epoch: 50 cost= 1084.831510198\n",
      "Epoch: 50; Dev perplexity = 583.3697\n",
      "Epoch: 60 cost= 1073.562798212\n",
      "Epoch: 60; Dev perplexity = 569.5642\n",
      "Epoch: 70 cost= 1062.651181488\n",
      "Epoch: 70; Dev perplexity = 558.2651\n",
      "Epoch: 80 cost= 1064.949063636\n",
      "Epoch: 80; Dev perplexity = 544.8938\n",
      "Epoch: 90 cost= 1075.420855836\n",
      "Epoch: 90; Dev perplexity = 534.3719\n",
      "Epoch: 100 cost= 1084.411932414\n",
      "Epoch: 100; Dev perplexity = 526.7185\n",
      "Epoch: 110 cost= 1079.140406530\n",
      "Epoch: 110; Dev perplexity = 521.7649\n",
      "Epoch: 120 cost= 1075.098781372\n",
      "Epoch: 120; Dev perplexity = 508.8820\n",
      "Epoch: 130 cost= 1092.186877359\n",
      "Epoch: 130; Dev perplexity = 493.8929\n",
      "Epoch: 140 cost= 1071.401804128\n",
      "Epoch: 140; Dev perplexity = 481.4670\n",
      "Background frequencies of top words:\n",
      "senator obama bill said senate today washington graham press president\n",
      "[0.01296816 0.01271263 0.00941629 0.00862415 0.00805176 0.00681244\n",
      " 0.00638571 0.00630138 0.00597941 0.00590275]\n",
      "Topics:\n",
      "0: veterans members guard service care benefits men soldiers  / energy enforcement public environmental sources contact power trade ; sparsity=0.0000\n",
      "1: court rights democratic supreme judge judiciary freedom united  / health grants billion cost projects energy amount training ; sparsity=0.0000\n",
      "2: lead children tax illegal immigration insurance millions pay  / regional browse facility serve east environment supreme army ; sparsity=0.0000\n",
      "3: departments grants fire share awarded assistance local receive  / reform statement american supreme america change votes simply ; sparsity=0.0000\n",
      "4: projects energy development environment million farmers transportation renewable  / supreme opinion ortiz statement recent initiated polls days ; sparsity=0.0000\n",
      "5: going court right little things always something let  / contact grants browse awarded demint grant announced receive ; sparsity=0.0000\n",
      "6: announced investigation letter record press relases releases statement  / bill tax floor energy billion amendment passed legislation ; sparsity=0.0000\n",
      "7: iraq troops war iraqi political terror win security  / grants grant demint awarded education rural receive energy ; sparsity=0.0000\n",
      "8: statement following released julian tommy barack washington nomination  / problem number levels health total reduce increase amount ; sparsity=0.0000\n",
      "9: energy oil gas renewable reduce prices sources climate  / military men troops provided members funding veterans war ; sparsity=0.0000\n",
      "sparsity in topics = 0.0000\n",
      "Covariate deviations:\n",
      "Coburn: room citizen spending coburn taxpayers released tom per  / browse contact tommy vietor petitions wes ortiz hickman ; sparsity=0.0000\n",
      "Graham: hickman bishop browse demint press grant releases lindsey  / obama tommy thursday durbin vietor pursuant release klobuchar ; sparsity=0.0000\n",
      "Klobuchar: klobuchar minnesota amy farmers prices serves commerce consumer  / obama browse bishop vietor demint polls graham tommy ; sparsity=0.0000\n",
      "McCain: browse john mccain land simply consequences though record  / contact tommy hickman petitions relases klobuchar ortiz durbin ; sparsity=0.0000\n",
      "Obama: vietor initiated pursuant polls obama tommy petitions brundage  / browse hickman press south graham relases bishop wes ; sparsity=0.0000\n",
      "Sanders: sanders bernie http sen told bush visit news  / contact browse petitions graham hickman criminal pursuant washington ; sparsity=0.0000\n",
      "sparsity in covariates = 0.0000\n",
      "Dev perplexity = 473.3764\n",
      "Saving document representations\n"
     ]
    }
   ],
   "source": [
    "script = 'run_scholar.py'\n",
    "args = 'tutorial/congress/ -k 10 --epochs 150 --dev-folds 10 --seed 99 --topic-covars senator --w2v ./vectors/GoogleNews-vectors-negative300.bin'\n",
    "print(\"python\", script, args)\n",
    "run_scholar.main(args.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: veterans members guard service care benefits men soldiers ; sparsity=0.0000\n",
      "1: court rights democratic supreme judge judiciary freedom united ; sparsity=0.0000\n",
      "2: lead children tax illegal immigration insurance millions pay ; sparsity=0.0000\n",
      "3: departments grants fire share awarded assistance local receive ; sparsity=0.0000\n",
      "4: projects energy development environment million farmers transportation renewable ; sparsity=0.0000\n",
      "5: going court right little things always something let ; sparsity=0.0000\n",
      "6: announced investigation letter record press relases releases statement ; sparsity=0.0000\n",
      "7: iraq troops war iraqi political terror win security ; sparsity=0.0000\n",
      "8: statement following released julian tommy barack washington nomination ; sparsity=0.0000\n",
      "9: energy oil gas renewable reduce prices sources climate ; sparsity=0.0000\n"
     ]
    }
   ],
   "source": [
    "beta = np.load('output/beta.npz')['beta']\n",
    "print_top_words(beta, vocab, n_pos=8, n_neg=0);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, the results seem quite similar, but it might be more beneficial when working with a larger vocabualry (and therefore words which occur less frequently)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding more covariates\n",
    "\n",
    "Note that we can easily include additional covarites in the same way as we did for senators. Let's try also including covariates for year and month. Just include them in a comma-separated list (again, without spaces)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python run_scholar.py tutorial/congress/ -k 10 --epochs 150 --dev-folds 10 --seed 99 --topic-covars senator,year,month\n",
      "Loading data\n",
      "Loaded 2483 documents with 1021 features\n",
      "Found 2483 non-empty documents\n",
      "Loading covariates from tutorial/congress/train.senator.csv\n",
      "Loading covariates from tutorial/congress/train.year.csv\n",
      "Loading covariates from tutorial/congress/train.month.csv\n",
      "Computing background frequencies\n",
      "Min/max word counts in training data: 88 5075\n",
      "Network architecture:\n",
      "embedding_dim: 300\n",
      "n_topics: 10\n",
      "vocab_size: 1021\n",
      "label_type: None\n",
      "n_labels: 0\n",
      "n_prior_covars: 0\n",
      "n_topic_covars: 22\n",
      "l1_beta_reg: 0.0\n",
      "l1_beta_c_reg: 0.0\n",
      "l1_beta_ci_reg: 0.0\n",
      "l2_prior_reg: 0.0\n",
      "classifier_layers: 1\n",
      "use_interactions: False\n",
      "Optimizing full model\n",
      "Epoch: 10 cost= 1129.572934144\n",
      "Epoch: 10; Dev perplexity = 860.8310\n",
      "Epoch: 20 cost= 1091.396167593\n",
      "Epoch: 20; Dev perplexity = 766.9607\n",
      "Epoch: 30 cost= 1087.384221634\n",
      "Epoch: 30; Dev perplexity = 714.8554\n",
      "Epoch: 40 cost= 1053.508688566\n",
      "Epoch: 40; Dev perplexity = 659.0192\n",
      "Epoch: 50 cost= 1074.958823799\n",
      "Epoch: 50; Dev perplexity = 625.7563\n",
      "Epoch: 60 cost= 1059.172663678\n",
      "Epoch: 60; Dev perplexity = 611.8233\n",
      "Epoch: 70 cost= 1039.878508634\n",
      "Epoch: 70; Dev perplexity = 579.7950\n",
      "Epoch: 80 cost= 1057.128562159\n",
      "Epoch: 80; Dev perplexity = 558.4165\n",
      "Epoch: 90 cost= 1037.520290434\n",
      "Epoch: 90; Dev perplexity = 531.3960\n",
      "Epoch: 100 cost= 1055.141825495\n",
      "Epoch: 100; Dev perplexity = 515.9899\n",
      "Epoch: 110 cost= 1060.904827758\n",
      "Epoch: 110; Dev perplexity = 499.0301\n",
      "Epoch: 120 cost= 1074.686549654\n",
      "Epoch: 120; Dev perplexity = 476.8179\n",
      "Epoch: 130 cost= 1098.103415129\n",
      "Epoch: 130; Dev perplexity = 459.3844\n",
      "Epoch: 140 cost= 1074.672267154\n",
      "Epoch: 140; Dev perplexity = 446.1821\n",
      "Background frequencies of top words:\n",
      "senator obama bill said senate today washington graham press president\n",
      "[0.01296816 0.01271263 0.00941629 0.00862415 0.00805176 0.00681244\n",
      " 0.00638571 0.00630138 0.00597941 0.00590275]\n",
      "Topics:\n",
      "0: energy fuels gas renewable fuel oil reduce climate  / military afghanistan iraq members war department funding armed ; sparsity=0.0000\n",
      "1: troops iraq terror war political freedom win bring  / department program million receive grants programs funds total ; sparsity=0.0000\n",
      "2: earmarks taxpayer transparency taxpayers spending projects accountability appropriations  / united children lose areas young states grant city ; sparsity=0.0000\n",
      "3: counties residents disaster assistance damage grants departments emergency  / american reform called statement americans debate introduced believe ; sparsity=0.0000\n",
      "4: announces announced awarded grant school carolina south development  / president even back reform amendment people court time ; sparsity=0.0000\n",
      "5: statement nomination released following supreme judge court judiciary  / number increase provide additional increased program funds funding ; sparsity=0.0000\n",
      "6: veterans care returning services medical guard members affairs  / interest people statement political security politics vote stop ; sparsity=0.0000\n",
      "7: letter sincerely hearing dear writing concerns workers investigation  / funding funds million families fiscal billion grants troops ; sparsity=0.0000\n",
      "8: soldiers war iraq say let afghanistan back troops  / energy carolina contact south announced grants development grant ; sparsity=0.0000\n",
      "9: children illegal immigration lead products parents border income  / war iraq military general brave armed afghanistan members ; sparsity=0.0000\n",
      "sparsity in topics = 0.0000\n",
      "Covariate deviations:\n",
      "Coburn: room citizen coburn tom per released spending added  / bishop graham tommy contact obama gibbs hickman relases ; sparsity=0.0000\n",
      "Graham: bishop graham relases kevin lindsey south hickman carolina  / tommy klobuchar barack wednesday gibbs illinois obama tuesday ; sparsity=0.0000\n",
      "Klobuchar: klobuchar minnesota consumer secured guard serves farm transportation  / barack polls bishop graham releases kevin mccain contact ; sparsity=0.0000\n",
      "McCain: mccain john record browse freedom remains air democracy  / obama barack contact gibbs hickman carolina vietor tommy ; sparsity=0.0000\n",
      "Obama: obama julian illinois barack brundage dick alerts gibbs  / bishop klobuchar releases lindsey press mccain minnesota south ; sparsity=0.0000\n",
      "Sanders: sanders http bernie sen vermont read paying told  / barack graham obama klobuchar labolt ben mccain amy ; sparsity=0.0000\n",
      "2005: gibbs julian vietor announces green tommy robert court  / alerts initiated newsletters pursuant ortiz brundage electronic period ; sparsity=0.0000\n",
      "2006: vietor tommy gibbs robert julian alternative green authority  / alerts petitions newsletters ortiz initiated brundage pursuant polls ; sparsity=0.0000\n",
      "2007: labolt ben brundage amy http iraq course visit  / julian gibbs tommy vietor ortiz robert alerts green ; sparsity=0.0000\n",
      "2008: newsletters petitions polls initiated michael alerts ortiz pursuant  / labolt tommy gibbs ben julian vietor graham brundage ; sparsity=0.0000\n",
      "Apr: april location temporary drug prices price calls attention  / june september august july complete quickly terror november ; sparsity=0.0000\n",
      "Aug: august transportation insurance office children area receive letter  / finally union decades head known clinton allowing expected ; sparsity=0.0000\n",
      "Dec: december polls petitions initiated electronic pursuant newsletters alerts  / ben june supporting third august labolt company illinois ; sparsity=0.0000\n",
      "Feb: february cut eliminate budget debate short resolution hear  / established september along august veto june april brundage ; sparsity=0.0000\n",
      "Jan: january economic things judiciary sources congress decisions class  / september june estimated loss payments july april company ; sparsity=0.0000\n",
      "Jul: july labolt ways established measures secured moving hearing  / brundage october november april september class august amy ; sparsity=0.0000\n",
      "Jun: june initiative immigration along system find opportunities data  / september amy december presidents august april october january ; sparsity=0.0000\n",
      "Mar: march budget subject paid conditions trust labolt resolution  / june september august brundage site respect month supreme ; sparsity=0.0000\n",
      "May: immigration site domestic permanent asking workers committed takes  / september june october december brundage amy august july ; sparsity=0.0000\n",
      "Nov: november brundage alerts pursuant polls petitions initiated period  / labolt june ben july close noted approach january ; sparsity=0.0000\n",
      "Oct: october brundage amy human cases values age private  / labolt june often ben improving january leaders moving ; sparsity=0.0000\n",
      "Sep: september chief brundage view ahead terror recovery presidents  / labolt june january november initiated alerts december second ; sparsity=0.0000\n",
      "sparsity in covariates = 0.0000\n",
      "Dev perplexity = 438.8745\n",
      "Saving document representations\n"
     ]
    }
   ],
   "source": [
    "script = 'run_scholar.py'\n",
    "args = 'tutorial/congress/ -k 10 --epochs 150 --dev-folds 10 --seed 99 --topic-covars senator,year,month'\n",
    "print(\"python\", script, args)\n",
    "run_scholar.main(args.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now if we load the covariate vectors, we will also see some temporal patterns in word frequencies. The ones here don't seem all that compelling, but perhaps more data is needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coburn: room citizen coburn tom per released spending added ; sparsity=0.0000\n",
      "Graham: bishop graham relases kevin lindsey south hickman carolina ; sparsity=0.0000\n",
      "Klobuchar: klobuchar minnesota consumer secured guard serves farm transportation ; sparsity=0.0000\n",
      "McCain: mccain john record browse freedom remains air democracy ; sparsity=0.0000\n",
      "Obama: obama julian illinois barack brundage dick alerts gibbs ; sparsity=0.0000\n",
      "Sanders: sanders http bernie sen vermont read paying told ; sparsity=0.0000\n",
      "2005: gibbs julian vietor announces green tommy robert court ; sparsity=0.0000\n",
      "2006: vietor tommy gibbs robert julian alternative green authority ; sparsity=0.0000\n",
      "2007: labolt ben brundage amy http iraq course visit ; sparsity=0.0000\n",
      "2008: newsletters petitions polls initiated michael alerts ortiz pursuant ; sparsity=0.0000\n",
      "Apr: april location temporary drug prices price calls attention ; sparsity=0.0000\n",
      "Aug: august transportation insurance office children area receive letter ; sparsity=0.0000\n",
      "Dec: december polls petitions initiated electronic pursuant newsletters alerts ; sparsity=0.0000\n",
      "Feb: february cut eliminate budget debate short resolution hear ; sparsity=0.0000\n",
      "Jan: january economic things judiciary sources congress decisions class ; sparsity=0.0000\n",
      "Jul: july labolt ways established measures secured moving hearing ; sparsity=0.0000\n",
      "Jun: june initiative immigration along system find opportunities data ; sparsity=0.0000\n",
      "Mar: march budget subject paid conditions trust labolt resolution ; sparsity=0.0000\n",
      "May: immigration site domestic permanent asking workers committed takes ; sparsity=0.0000\n",
      "Nov: november brundage alerts pursuant polls petitions initiated period ; sparsity=0.0000\n",
      "Oct: october brundage amy human cases values age private ; sparsity=0.0000\n",
      "Sep: september chief brundage view ahead terror recovery presidents ; sparsity=0.0000\n"
     ]
    }
   ],
   "source": [
    "topic_covars = np.load(os.path.join('output', 'beta_c.npz'))\n",
    "weights = topic_covars['beta']\n",
    "names = topic_covars['names']\n",
    "print_top_words(weights, vocab, topic_names=names, n_pos=8, n_neg=0);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactions\n",
    "\n",
    "Alternatively, we can include interactions between covariates and topics.\n",
    "\n",
    "Here, let's try using a covariate for party membership, rather than for each Senator, and include interactions between topics and party. To do this, just include the `--interactions` options. We'll also use less topics, since we'll effectively be getting two versions of each (Democrat and Republican)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python run_scholar.py tutorial/congress/ -k 8 --epochs 150 --dev-folds 10 --seed 99 --topic-covars party --interactions\n",
      "Loading data\n",
      "Loaded 2483 documents with 1021 features\n",
      "Found 2483 non-empty documents\n",
      "Loading covariates from tutorial/congress/train.party.csv\n",
      "Computing background frequencies\n",
      "Min/max word counts in training data: 88 5075\n",
      "Network architecture:\n",
      "embedding_dim: 300\n",
      "n_topics: 8\n",
      "vocab_size: 1021\n",
      "label_type: None\n",
      "n_labels: 0\n",
      "n_prior_covars: 0\n",
      "n_topic_covars: 2\n",
      "l1_beta_reg: 0.0\n",
      "l1_beta_c_reg: 0.0\n",
      "l1_beta_ci_reg: 0.0\n",
      "l2_prior_reg: 0.0\n",
      "classifier_layers: 1\n",
      "use_interactions: True\n",
      "Optimizing full model\n",
      "Epoch: 10 cost= 1158.523839485\n",
      "Epoch: 10; Dev perplexity = 920.8193\n",
      "Epoch: 20 cost= 1113.416789010\n",
      "Epoch: 20; Dev perplexity = 803.6328\n",
      "Epoch: 30 cost= 1108.656210675\n",
      "Epoch: 30; Dev perplexity = 752.6608\n",
      "Epoch: 40 cost= 1076.031638877\n",
      "Epoch: 40; Dev perplexity = 684.2396\n",
      "Epoch: 50 cost= 1097.876675668\n",
      "Epoch: 50; Dev perplexity = 642.9678\n",
      "Epoch: 60 cost= 1079.306651549\n",
      "Epoch: 60; Dev perplexity = 618.0787\n",
      "Epoch: 70 cost= 1058.343727061\n",
      "Epoch: 70; Dev perplexity = 592.6020\n",
      "Epoch: 80 cost= 1075.167976396\n",
      "Epoch: 80; Dev perplexity = 572.7244\n",
      "Epoch: 90 cost= 1054.995876372\n",
      "Epoch: 90; Dev perplexity = 550.2364\n",
      "Epoch: 100 cost= 1071.333340980\n",
      "Epoch: 100; Dev perplexity = 532.7445\n",
      "Epoch: 110 cost= 1075.331687159\n",
      "Epoch: 110; Dev perplexity = 514.3380\n",
      "Epoch: 120 cost= 1090.401182580\n",
      "Epoch: 120; Dev perplexity = 497.7988\n",
      "Epoch: 130 cost= 1116.593091312\n",
      "Epoch: 130; Dev perplexity = 482.7604\n",
      "Epoch: 140 cost= 1095.303804880\n",
      "Epoch: 140; Dev perplexity = 472.0555\n",
      "Background frequencies of top words:\n",
      "senator obama bill said senate today washington graham press president\n",
      "[0.01296816 0.01271263 0.00941629 0.00862415 0.00805176 0.00681244\n",
      " 0.00638571 0.00630138 0.00597941 0.00590275]\n",
      "Topics:\n",
      "0: immigration illegal temporary pursuant polls border opinion alerts  / minnesota soldiers million projects klobuchar vermont funding program ; sparsity=0.0000\n",
      "1: dick durbin request individual disaster severe communications letter  / south hickman carolina sanders relases vermont energy graham ; sparsity=0.0000\n",
      "2: grants vehicles equipment fire tools energy departments supports  / statement opinion coburn ortiz alerts process people regarding ; sparsity=0.0000\n",
      "3: iraq troops war say strategy let different things  / barack initiated alerts release gibbs julian ortiz electronic ; sparsity=0.0000\n",
      "4: announces announced bishop development lindsey awarded minnesota hickman  / veterans barack percent obama even introduced americans require ; sparsity=0.0000\n",
      "5: room lead products transparency coburn consumer spending citizen  / south hickman carolina relases releases graham date alerts ; sparsity=0.0000\n",
      "6: statement court nomination justice attorney following julian passing  / million percent veterans increase klobuchar programs health energy ; sparsity=0.0000\n",
      "7: guard care health soldiers members returning duty mental  / alerts opinion sincerely immediately ortiz letter international vietor ; sparsity=0.0010\n",
      "sparsity in topics = 0.0001\n",
      "Covariate deviations:\n",
      "D: barack ortiz fuel illinois gibbs newsletters monday vietor  / browse relases hickman mccain carolina south citizen record ; sparsity=0.0000\n",
      "R: releases announce carolina south kevin graham judiciary fire  / amy barack labolt thursday tommy minnesota alerts julian ; sparsity=0.0000\n",
      "sparsity in covariates = 0.0000\n",
      "Covariate interactions\n",
      "(16, 1021)\n",
      "0:D: alerts petitions opinion polls newsletters electronic communications initiated  / hickman press minnesota funding relases state klobuchar south ; sparsity=0.0000\n",
      "0:R: immigration illegal border secure states laws reform trade  / barack ortiz opinion polls primary initiated alerts newsletters ; sparsity=0.0000\n",
      "1:D: durbin dick counties sincerely disaster illinois severe opinion  / browse bills prices nations mccain voted change energy ; sparsity=0.0000\n",
      "1:R: almost act bills largest report manner mccain around  / barack contact ortiz amy labolt south carolina gibbs ; sparsity=0.0000\n",
      "2:D: gas technologies energy environment oil economy standard efficient  / relases hickman carolina graham statement opinion ortiz awarded ; sparsity=0.0000\n",
      "2:R: grants awarded demint tools supports receive fire contributions  / estimated already klobuchar take supported raise alone per ; sparsity=0.0000\n",
      "3:D: sanders bernie warming vermont http read reality global  / releases contact browse graham hickman relases criminal immediately ; sparsity=0.0000\n",
      "3:R: terror political war strategy consequences win chance iraq  / bernie vermont million programs department labolt program health ; sparsity=0.0000\n",
      "4:D: minnesota klobuchar transportation environment secured works subcommittee line  / hickman relases press bishop lindsey graham wes date ; sparsity=0.0000\n",
      "4:R: announces contact releases browse date relases carolina announced  / barack minnesota klobuchar last without act just giving ; sparsity=0.0000\n",
      "5:D: lead products consumer children commission safety practices industry  / statement line assistance war alerts releases projects per ; sparsity=0.0000\n",
      "5:R: coburn room spending debt earmarks per associated citizen  / hickman contact klobuchar kevin south relases graham carolina ; sparsity=0.0000\n",
      "6:D: julian tommy statement gibbs obama immediate vietor contact  / browse hickman releases percent relases press wes per ; sparsity=0.0000\n",
      "6:R: mccain supreme browse john man court experience highest  / barack million electronic provide fiscal initiated alerts gibbs ; sparsity=0.0000\n",
      "7:D: returning veterans soldiers health income vermont guard care  / coburn relases hickman carolina browse releases press international ; sparsity=0.0000\n",
      "7:R: coburn per room guard care citizen true eligible  / minnesota klobuchar strengthen amy vermont returning come obama ; sparsity=0.0000\n",
      "sparsity in covariate interactions = 0.0000\n",
      "Dev perplexity = 464.6003\n",
      "Saving document representations\n"
     ]
    }
   ],
   "source": [
    "script = 'run_scholar.py'\n",
    "args = 'tutorial/congress/ -k 8 --epochs 150 --dev-folds 10 --seed 99 --topic-covars party --interactions'\n",
    "print(\"python\", script, args)\n",
    "run_scholar.main(args.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's look at the vectors learned for each party, then the topics, then the interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D: barack ortiz fuel illinois gibbs newsletters monday vietor ; sparsity=0.0000\n",
      "R: releases announce carolina south kevin graham judiciary fire ; sparsity=0.0000\n"
     ]
    }
   ],
   "source": [
    "topic_covars = np.load(os.path.join('output', 'beta_c.npz'))\n",
    "weights = topic_covars['beta']\n",
    "names = topic_covars['names']\n",
    "print_top_words(weights, vocab, topic_names=names, n_pos=8, n_neg=0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: immigration illegal temporary pursuant polls border opinion alerts ; sparsity=0.0000\n",
      "1: dick durbin request individual disaster severe communications letter ; sparsity=0.0000\n",
      "2: grants vehicles equipment fire tools energy departments supports ; sparsity=0.0000\n",
      "3: iraq troops war say strategy let different things ; sparsity=0.0000\n",
      "4: announces announced bishop development lindsey awarded minnesota hickman ; sparsity=0.0000\n",
      "5: room lead products transparency coburn consumer spending citizen ; sparsity=0.0000\n",
      "6: statement court nomination justice attorney following julian passing ; sparsity=0.0000\n",
      "7: guard care health soldiers members returning duty mental ; sparsity=0.0010\n"
     ]
    }
   ],
   "source": [
    "beta = np.load(os.path.join('output', 'beta.npz'))['beta']\n",
    "print_top_words(beta, vocab, n_pos=8, n_neg=0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:D: alerts petitions opinion polls newsletters electronic communications initiated ; sparsity=0.0000\n",
      "0:R: immigration illegal border secure states laws reform trade ; sparsity=0.0000\n",
      "1:D: durbin dick counties sincerely disaster illinois severe opinion ; sparsity=0.0000\n",
      "1:R: almost act bills largest report manner mccain around ; sparsity=0.0000\n",
      "2:D: gas technologies energy environment oil economy standard efficient ; sparsity=0.0000\n",
      "2:R: grants awarded demint tools supports receive fire contributions ; sparsity=0.0000\n",
      "3:D: sanders bernie warming vermont http read reality global ; sparsity=0.0000\n",
      "3:R: terror political war strategy consequences win chance iraq ; sparsity=0.0000\n",
      "4:D: minnesota klobuchar transportation environment secured works subcommittee line ; sparsity=0.0000\n",
      "4:R: announces contact releases browse date relases carolina announced ; sparsity=0.0000\n",
      "5:D: lead products consumer children commission safety practices industry ; sparsity=0.0000\n",
      "5:R: coburn room spending debt earmarks per associated citizen ; sparsity=0.0000\n",
      "6:D: julian tommy statement gibbs obama immediate vietor contact ; sparsity=0.0000\n",
      "6:R: mccain supreme browse john man court experience highest ; sparsity=0.0000\n",
      "7:D: returning veterans soldiers health income vermont guard care ; sparsity=0.0000\n",
      "7:R: coburn per room guard care citizen true eligible ; sparsity=0.0000\n"
     ]
    }
   ],
   "source": [
    "interactions = np.load(os.path.join('output', 'beta_ci.npz'))\n",
    "weights = interactions['beta']\n",
    "names = topic_covars['names']\n",
    "names = [str(k) + ':' + c for k in range(10) for c in names]\n",
    "print_top_words(weights, vocab, topic_names=names, n_pos=8, n_neg=0);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The basic topics here are now perhaps less good, but the interaction do seem to capture something about how the different parties talk about certain issues. For example, for topic 0 (immigration), The Democrat version emphasizes public opinion, whereas the republican version is more about border security. More data (from all the senators) would give us a much better approxaimation of this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to covariates, we can also introduce labels, which are predicted from the topics that are learned. Although they only introduce a subtle influence on the topic, we are effectively learning a classifier and a topic model simultaneously.\n",
    "\n",
    "Here, let's try predicting the party of a press release from the topics. We'll also try using slightly more topics this time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python run_scholar.py tutorial/congress/ -k 12 --epochs 150 --dev-folds 10 --seed 99 --topic-covars senator,month --label party\n",
      "Loading data\n",
      "Loaded 2483 documents with 1021 features\n",
      "Found 2483 non-empty documents\n",
      "Loading labels from tutorial/congress/train.party.csv\n",
      "Found 2 labels\n",
      "Loading covariates from tutorial/congress/train.senator.csv\n",
      "Loading covariates from tutorial/congress/train.month.csv\n",
      "Train label proportions: [0.54007249 0.45992751]\n",
      "Computing background frequencies\n",
      "Min/max word counts in training data: 88 5075\n",
      "Network architecture:\n",
      "embedding_dim: 300\n",
      "n_topics: 12\n",
      "vocab_size: 1021\n",
      "label_type: None\n",
      "n_labels: 2\n",
      "n_prior_covars: 0\n",
      "n_topic_covars: 18\n",
      "l1_beta_reg: 0.0\n",
      "l1_beta_c_reg: 0.0\n",
      "l1_beta_ci_reg: 0.0\n",
      "l2_prior_reg: 0.0\n",
      "classifier_layers: 1\n",
      "use_interactions: False\n",
      "Optimizing full model\n",
      "Epoch: 10 ; cost = 1136.633699490 ; training accuracy (noisy) = 0.702013423\n",
      "Epoch: 10; Dev perplexity = 909.2849; Dev accuracy = 0.7177\n",
      "Epoch: 20 ; cost = 1095.048931898 ; training accuracy (noisy) = 0.574496644\n",
      "Epoch: 20; Dev perplexity = 858.1822; Dev accuracy = 0.6895\n",
      "Epoch: 30 ; cost = 1090.597363500 ; training accuracy (noisy) = 0.615212528\n",
      "Epoch: 30; Dev perplexity = 773.6793; Dev accuracy = 0.6935\n",
      "Epoch: 40 ; cost = 1058.631818460 ; training accuracy (noisy) = 0.627740492\n",
      "Epoch: 40; Dev perplexity = 708.0969; Dev accuracy = 0.6694\n",
      "Epoch: 50 ; cost = 1079.181888589 ; training accuracy (noisy) = 0.632214765\n",
      "Epoch: 50; Dev perplexity = 669.1317; Dev accuracy = 0.6774\n",
      "Epoch: 60 ; cost = 1064.260548841 ; training accuracy (noisy) = 0.633109620\n",
      "Epoch: 60; Dev perplexity = 641.4088; Dev accuracy = 0.6855\n",
      "Epoch: 70 ; cost = 1045.057637942 ; training accuracy (noisy) = 0.646085011\n",
      "Epoch: 70; Dev perplexity = 602.9703; Dev accuracy = 0.6976\n",
      "Epoch: 80 ; cost = 1062.571112102 ; training accuracy (noisy) = 0.637583893\n",
      "Epoch: 80; Dev perplexity = 581.0854; Dev accuracy = 0.7177\n",
      "Epoch: 90 ; cost = 1043.376557694 ; training accuracy (noisy) = 0.672483221\n",
      "Epoch: 90; Dev perplexity = 555.0756; Dev accuracy = 0.7056\n",
      "Epoch: 100 ; cost = 1061.386614977 ; training accuracy (noisy) = 0.661297539\n",
      "Epoch: 100; Dev perplexity = 536.6641; Dev accuracy = 0.7702\n",
      "Epoch: 110 ; cost = 1067.902897572 ; training accuracy (noisy) = 0.696644295\n",
      "Epoch: 110; Dev perplexity = 523.7696; Dev accuracy = 0.8024\n",
      "Epoch: 120 ; cost = 1082.092181383 ; training accuracy (noisy) = 0.693959732\n",
      "Epoch: 120; Dev perplexity = 502.5767; Dev accuracy = 0.8185\n",
      "Epoch: 130 ; cost = 1105.137046456 ; training accuracy (noisy) = 0.701565996\n",
      "Epoch: 130; Dev perplexity = 483.9952; Dev accuracy = 0.8266\n",
      "Epoch: 140 ; cost = 1082.585864312 ; training accuracy (noisy) = 0.699776286\n",
      "Epoch: 140; Dev perplexity = 468.6756; Dev accuracy = 0.8185\n",
      "Background frequencies of top words:\n",
      "senator obama bill said senate today washington graham press president\n",
      "[0.01296816 0.01271263 0.00941629 0.00862415 0.00805176 0.00681244\n",
      " 0.00638571 0.00630138 0.00597941 0.00590275]\n",
      "Topics:\n",
      "0: troops iraq course strategy iraqi war forces tell  / department demint announced awarded funds program letter grants ; sparsity=0.0000\n",
      "1: members veterans care returning military service soldiers defense  / industry statement justice interest clean energy record companies ; sparsity=0.0000\n",
      "2: immigration border investigation information illegal accountability workers reports  / statement change clean east great demint troops environment ; sparsity=0.0000\n",
      "3: nomination statement position following supreme judge court wes  / million providing health grants equipment fiscal care cost ; sparsity=0.0000\n",
      "4: court supreme judge justice judiciary election rules democratic  / health million funding care programs billion demint fiscal ; sparsity=0.0000\n",
      "5: students environment project river climate development education funding  / statement immediately date call iraq letter troops general ; sparsity=0.0000\n",
      "6: counties products disaster safety homes lead dick assistance  / americans statement military war veterans change policies joint ; sparsity=0.0000\n",
      "7: energy gas renewable oil fuels fuel sources consumers  / care statement war polls region primary troops military ; sparsity=0.0000\n",
      "8: awarded announces grant grants announce announced receive demint  / senate united president believe time now nation issue ; sparsity=0.0000\n",
      "9: statement released following newsletters petitions initiated pursuant opinion  / amount number provide year percent cost available average ; sparsity=0.0000\n",
      "10: priorities spending earmarks billion fiscal veto bills budget  / united general justice criminal michael court communications role ; sparsity=0.0000\n",
      "11: statement released following newsletters ortiz pursuant initiated petitions  / average billion fiscal provide percent year bill providing ; sparsity=0.0000\n",
      "sparsity in topics = 0.0000\n",
      "Covariate deviations:\n",
      "Coburn: coburn tom citizen per room released financial congress  / bernie minnesota date graham vietor obama petitions browse ; sparsity=0.0000\n",
      "Graham: hickman lindsey kevin south releases relases graham demint  / vietor thursday klobuchar pursuant immediately obama gibbs bernie ; sparsity=0.0000\n",
      "Klobuchar: klobuchar minnesota amy serves transportation secured consumer cities  / obama barack press browse labolt graham vietor lindsey ; sparsity=0.0000\n",
      "McCain: mccain browse john record defense simply freedom air  / kevin hickman vietor obama graham carolina thursday barack ; sparsity=0.0010\n",
      "Obama: immediate labolt obama gibbs ben tommy brundage barack  / hickman minnesota graham kevin klobuchar carolina bernie bishop ; sparsity=0.0000\n",
      "Sanders: bernie sen read vermont http paying sanders visit  / minnesota obama date klobuchar kevin carolina hickman barack ; sparsity=0.0000\n",
      "Apr: april location temporary prices price building ortiz drug  / july august june vietor tommy brundage september complete ; sparsity=0.0000\n",
      "Aug: august transportation receive children announce criminal grant insurance  / polls initiated finally newsletters supports expected sense union ; sparsity=0.0000\n",
      "Dec: december farm petitions pursuant homes electronic provision alerts  / ben advance june august company labolt clearly announces ; sparsity=0.0000\n",
      "Feb: february cut eliminate introduce bipartisan affected budget provided  / june august april labolt along ways veto done ; sparsity=0.0000\n",
      "Jan: january sources economic class decisions middle union push  / estimated october april july september june voted immigration ; sparsity=0.0000\n",
      "Jul: july ways debt measures moving secured sure improving  / october april november class february brundage executive amy ; sparsity=0.0000\n",
      "Jun: june immigration along businesses initiative system laws almost  / amy october august authorized september march december july ; sparsity=0.0000\n",
      "Mar: march budget labolt subject resolution paid play rates  / brundage july october june august supreme amy run ; sparsity=0.0000\n",
      "May: immigration site domestic permanent asking committed takes joint  / july october august concerned september terrorists amy june ; sparsity=0.0000\n",
      "Nov: november brundage amy petitions win encourage authorized veto  / noted ortiz july june labolt approach close measure ; sparsity=0.0000\n",
      "Oct: october brundage amy human reported north values democratic  / labolt ortiz often polls initiated newsletters june alerts ; sparsity=0.0000\n",
      "Sep: september ahead brundage view recovery chief infrastructure terror  / alerts initiated ortiz polls newsletters petitions electronic labolt ; sparsity=0.0010\n",
      "sparsity in covariates = 0.0001\n",
      "Dev perplexity = 459.1609\n",
      "Predicting labels\n",
      "train accuracy on labels = 0.8067\n",
      "dev accuracy on labels = 0.8226\n",
      "Label probabilities based on topics\n",
      "Labels: D R\n",
      "0: 0.4957 0.5043 \n",
      "1: 0.8430 0.1570 \n",
      "2: 0.7062 0.2938 \n",
      "3: 0.0118 0.9882 \n",
      "4: 0.4418 0.5582 \n",
      "5: 0.8312 0.1688 \n",
      "6: 0.9481 0.0519 \n",
      "7: 0.8732 0.1268 \n",
      "8: 0.0095 0.9905 \n",
      "9: 0.9101 0.0899 \n",
      "10: 0.3079 0.6921 \n",
      "11: 0.5719 0.4281 \n",
      "Saving document representations\n"
     ]
    }
   ],
   "source": [
    "script = 'run_scholar.py'\n",
    "args = 'tutorial/congress/ -k 12 --epochs 150 --dev-folds 10 --seed 99 --topic-covars senator,month --label party'\n",
    "print(\"python\", script, args)\n",
    "run_scholar.main(args.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's look at the topics as usual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: troops iraq course strategy iraqi war forces tell ; sparsity=0.0000\n",
      "1: members veterans care returning military service soldiers defense ; sparsity=0.0000\n",
      "2: immigration border investigation information illegal accountability workers reports ; sparsity=0.0000\n",
      "3: nomination statement position following supreme judge court wes ; sparsity=0.0000\n",
      "4: court supreme judge justice judiciary election rules democratic ; sparsity=0.0000\n",
      "5: students environment project river climate development education funding ; sparsity=0.0000\n",
      "6: counties products disaster safety homes lead dick assistance ; sparsity=0.0000\n",
      "7: energy gas renewable oil fuels fuel sources consumers ; sparsity=0.0000\n",
      "8: awarded announces grant grants announce announced receive demint ; sparsity=0.0000\n",
      "9: statement released following newsletters petitions initiated pursuant opinion ; sparsity=0.0000\n",
      "10: priorities spending earmarks billion fiscal veto bills budget ; sparsity=0.0000\n",
      "11: statement released following newsletters ortiz pursuant initiated petitions ; sparsity=0.0000\n"
     ]
    }
   ],
   "source": [
    "beta = np.load(os.path.join('output', 'beta.npz'))['beta']\n",
    "print_top_words(beta, vocab, n_pos=8, n_neg=0);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look at which topics predict Democrat vs Republican."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels: D R\n",
      "0: 0.4957 0.5043 \n",
      "1: 0.8430 0.1570 \n",
      "2: 0.7062 0.2938 \n",
      "3: 0.0118 0.9882 \n",
      "4: 0.4418 0.5582 \n",
      "5: 0.8312 0.1688 \n",
      "6: 0.9481 0.0519 \n",
      "7: 0.8732 0.1268 \n",
      "8: 0.0095 0.9905 \n",
      "9: 0.9101 0.0899 \n",
      "10: 0.3079 0.6921 \n",
      "11: 0.5719 0.4281 \n"
     ]
    }
   ],
   "source": [
    "npz = np.load('output/topics_to_labels.npz')\n",
    "probs = npz['probs']\n",
    "label_names = npz['label']\n",
    "n_topics, n_labels = probs.shape\n",
    "print(\"Labels:\", ' '.join([name for name in label_names]))\n",
    "for k in range(n_topics):\n",
    "    output = str(k) + ': '\n",
    "    for i in range(n_labels):\n",
    "        output += '%.4f ' % probs[k, i]\n",
    "    print(output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These numbers show the probability (according to the model) that a document entirely about a single topic is from a Democrat vs a Republican. Of course, in practice, most documents will be represented as a mixture of topics, and both parties talk about all topics to some degree.\n",
    "\n",
    "More expertise would be useful in trying to interpret whether the model is doing something reasonable here, but at least some parts seem to line up (e.g. Democrats talking more about veterans (topic 1) and Republicans talking more about spending (topic 11). As above, using data from more Senators would be very useful here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ultimately, exploration of different models is requried to figure out what is best for your application. Also, remember than trying a different random seed will give you different results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
